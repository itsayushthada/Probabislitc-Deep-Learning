{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Explanation of saved files.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NR6NduoIo_9"
      },
      "source": [
        "# Explanation of saved files\n",
        "In this reading, we'll take a closer look at the files saved by the ModelCheckpoint callback, when saving weights only. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GShQsR8ZIpAB"
      },
      "source": [
        "Previously, you experimented with the ModelCheckpoint callback, which can be used to save model weights during training. You looked at the saved files using the `! ls` command. The saved files were the following:\n",
        "\n",
        "```\n",
        "-rw-r--r--  1 aph416  staff    87B  2 Nov 17:04 checkpoint\n",
        "-rw-r--r--  1 aph416  staff   2.0K  2 Nov 17:04 checkpoint.index\n",
        "-rw-r--r--  1 aph416  staff   174K  2 Nov 17:04 checkpoint.data-00000-of-00001\n",
        "```\n",
        "\n",
        "So, what are each of these files?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rznw7NVaIpAD"
      },
      "source": [
        "#### `checkpoint`\n",
        "This file is by far the smallest, at only 87 bytes. It's actually so small that we can just look at it directly. It's a human readable file with the following text:\n",
        "```\n",
        "model_checkpoint_path: \"checkpoint\"\n",
        "all_model_checkpoint_paths: \"checkpoint\"\n",
        "```\n",
        "This is metadata that indicates where the actual model data is stored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoFQmH3IpAF"
      },
      "source": [
        "#### `checkpoint.index`\n",
        "This file tells TensorFlow which weights are stored where. When running models on distributed systems, there may be different *shards*, meaning the full model may have to be recomposed from multiple sources. In the last notebook, you created a single model on a single machine, so there is only one *shard* and all weights are stored in the same place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFs8P4AIpAG"
      },
      "source": [
        "#### `checkpoint.data-00000-of-00001`\n",
        "This file contains the actual weights from the model. It is by far the largest of the 3 files. Recall that the model you trained had around 14000 parameters, meaning this file is roughly 12 bytes per saved weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQAnQ2iIp6u"
      },
      "source": [
        "### Further reading and resources\n",
        "* https://www.tensorflow.org/tutorials/keras/save_and_load#what_are_these_files"
      ]
    }
  ]
}