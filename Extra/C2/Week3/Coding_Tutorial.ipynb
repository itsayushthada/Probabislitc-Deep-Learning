{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Coding_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b3PNw3gJDI7",
        "hcPUtmz-JDKZ",
        "Zo5rD5ZcJDK_",
        "UFuhReOm9xF7",
        "EUG6LF1MJDL0",
        "9Ti4kMquJDML"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk88Aw4NJDIy",
        "outputId": "d290bb2c-ed5b-4204-890c-905f53141f53"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG"
      },
      "source": [
        "# Import imdb\n",
        "\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9jYJCwXJDJK",
        "outputId": "a97e26a6-751c-4e1c-d4aa-4fce7a8c9b39"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39RwIt-pJDJQ",
        "outputId": "76bd52cd-745f-477a-ebf4-c5e0926fde08"
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "print(\"Train Data Shape: {}\".format(x_train.shape))\n",
        "print(\"Train Labels Shape: {}\".format(y_train.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Shape: (25000,)\n",
            "Train Labels Shape: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Viryy_PDJDJU",
        "outputId": "a00781e3-4a37-47a1-b3c0-fb901943c1f9"
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "print(\"Test Data Shape: {}\".format(x_test.shape))\n",
        "print(\"Test Labels Shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data Shape: (25000,)\n",
            "Test Labels Shape: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q6E6v-FJDJX",
        "outputId": "4a23c1fa-e4f5-4714-aade-2bb4af8399cb"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n",
        "print(x_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lbEqyjxJDJc",
        "outputId": "cc248924-663c-4bb8-9115-7caf902f5aa8"
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "print(y_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfzFxDj-JDJh",
        "outputId": "8e380b94-c1ea-4ad3-8174-f12a6c7b3c74"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "\n",
        "imdb.load_data(path=\"/content/imdb.npz\", index_from=3)\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuGfzZg3JDJv",
        "outputId": "2f7100f3-4bf7-4a9c-a766-307f7e717871"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "\n",
        "imdb.load_data(path=\"/content/imdb.npz\", num_words=500)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
              "         list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 2, 202, 14, 31, 6, 2, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 2]),\n",
              "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 2, 4, 114, 9, 55, 2, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 2, 35, 2, 2, 19, 2, 2, 5, 2, 2, 45, 55, 221, 15, 2, 2, 2, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 2, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 2, 5, 2, 15, 45, 2, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 2, 2, 7, 2, 2, 2, 5, 2, 30, 2, 2, 56, 4, 2, 5, 2, 2, 8, 4, 2, 398, 229, 10, 10, 13, 2, 2, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 2, 2, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 2, 2, 2, 39, 4, 2, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 2, 8, 169, 11, 374, 2, 25, 203, 28, 8, 2, 12, 125, 4, 2]),\n",
              "         list([1, 111, 2, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 2, 63, 29, 2, 220, 2, 2, 5, 17, 12, 2, 220, 2, 17, 6, 185, 132, 2, 16, 53, 2, 11, 2, 74, 4, 438, 21, 27, 2, 2, 8, 22, 107, 2, 2, 2, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 2, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 2, 2, 7, 4, 2, 2, 2, 2, 8, 2, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 2, 2, 2, 2, 17, 2, 42, 4, 2, 37, 473, 6, 2, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 2, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 2, 2, 5, 258, 12, 184, 2, 2, 5, 2, 2, 7, 4, 22, 2, 18, 2, 2, 2, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 2, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 2, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 2, 4, 2, 26, 2, 2, 11, 14, 2, 2, 12, 426, 28, 77, 2, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 2, 6, 2, 54, 2, 2, 98, 6, 2, 40, 2, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 2, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 2, 37, 2, 2, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 2, 8, 2, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 2, 10, 10, 2, 4, 58, 2, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 2, 8, 67, 14, 17, 6, 2, 44, 148, 2, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 2, 2, 27, 2, 7, 2, 4, 22, 2, 17, 6, 2, 2, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 2, 7, 101, 2, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 2, 9, 57, 2]),\n",
              "         ...,\n",
              "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 2, 2, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 2, 362, 80, 119, 12, 21, 2, 2]),\n",
              "         list([1, 11, 119, 241, 9, 4, 2, 20, 12, 468, 15, 94, 2, 2, 2, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 2, 46, 2, 9, 2, 5, 4, 2, 47, 8, 79, 90, 145, 164, 162, 50, 6, 2, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 2, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 2, 13, 2, 14, 20, 6, 2, 7, 470]),\n",
              "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 2, 2, 6, 2, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 2, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 2, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 2, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 2, 22, 2, 19, 2, 2, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 2, 25, 124, 4, 31, 12, 16, 93, 2, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMkXgUGaJDJy",
        "outputId": "e25c8573-80b8-4e29-9ee4-9b94f8d61f5a"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n",
        "imdb.load_data(path=\"/content/imdb.npz\", skip_top=10, oov_char=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([2, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 22665, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 21631, 336, 385, 39, 2, 172, 4536, 1111, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2025, 19, 14, 22, 2, 1920, 4613, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 2, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2223, 5244, 16, 480, 66, 3785, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 10311, 2, 2, 107, 117, 5952, 15, 256, 2, 31050, 2, 3766, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 12118, 1029, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 2, 194, 7486, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 2, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([2, 194, 1153, 194, 8255, 78, 228, 2, 2, 1463, 4369, 5012, 134, 26, 2, 715, 2, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 3103, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 35, 8163, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 19, 2, 1002, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 1543, 1905, 398, 2, 1649, 26, 6853, 2, 163, 11, 3215, 10156, 2, 1153, 2, 194, 775, 2, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 2, 2, 228, 2, 43, 36893, 1157, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 4373, 228, 8255, 2, 25249, 656, 245, 2350, 2, 2, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 2, 2, 371, 78, 22, 625, 64, 1382, 2, 2, 168, 145, 23, 2, 1690, 15, 16, 2, 1355, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 2, 86, 320, 35, 534, 19, 263, 4821, 1301, 2, 1873, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 1716, 43, 645, 662, 2, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 2, 106, 14, 6905, 1338, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2307, 51, 2, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
              "         ...,\n",
              "         list([2, 11, 2, 230, 245, 6401, 2, 2, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 2, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 2, 36, 28, 57, 1099, 21, 2, 140, 2, 703, 2, 11656, 84, 56, 18, 1644, 14, 2, 31, 2, 2, 9406, 1209, 2295, 26094, 1008, 18, 2, 20, 207, 110, 563, 12, 2, 2901, 17793, 2, 97, 2, 20, 53, 4767, 74, 2, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 2, 4065, 500, 2, 14492, 89, 364, 70, 29, 140, 2, 64, 4780, 11, 2, 2678, 26, 178, 2, 529, 443, 17793, 2, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2766, 234, 1119, 1574, 2, 496, 2, 139, 929, 2901, 17793, 7750, 2, 4241, 18, 2, 8497, 13164, 250, 11, 1818, 7561, 2, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 2, 2, 59, 11027, 2, 3586, 22459]),\n",
              "         list([2, 1446, 7079, 69, 72, 3305, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 2, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 2, 2, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 1814, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 2, 719, 3798, 13, 18, 31, 62, 40, 2, 7200, 2, 29455, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 21213, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
              "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 12815, 270, 14437, 2, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 2, 1310, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 4039, 9245, 2, 24, 2, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 2, 29043, 1603, 92, 1183, 2, 1310, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 6789, 85010, 2, 2, 66, 78, 1099, 2, 631, 1191, 2, 2642, 272, 191, 1070, 2, 7585, 2, 2197, 70907, 10755, 544, 2, 383, 1271, 848, 1468, 12183, 497, 16876, 2, 1597, 8778, 19280, 21, 60, 27, 239, 2, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 1791, 72, 2, 51, 2, 1739, 22, 2, 204, 131, 2])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 18142, 10698, 2, 2, 360, 2, 2, 177, 5760, 394, 354, 2, 123, 2, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 2, 717]),\n",
              "         list([2, 14, 22, 3443, 2, 176, 2, 5063, 88, 12, 2679, 23, 1310, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 7216, 10626, 2, 8463, 2801, 109, 1603, 21, 2, 22, 3861, 2, 2, 1193, 1330, 10, 10, 2, 105, 987, 35, 841, 16873, 19, 861, 1074, 2, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 2, 405, 2, 2438, 2, 27, 85, 108, 131, 2, 5045, 5304, 3884, 405, 2, 3523, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 8463, 2801, 45, 407, 31, 2, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 2, 4521, 15, 45, 629, 488, 2733, 127, 2, 52, 292, 17, 2, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 2, 392, 173, 2, 21686, 4378, 270, 2352, 2, 1500, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2078, 2, 5293, 861, 12746, 2, 4182, 30, 3127, 23651, 56, 2, 841, 2, 990, 692, 2, 2, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 2, 31, 2, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 2, 1193, 21, 45, 4829, 2, 45, 252, 2, 12508, 2, 565, 921, 3639, 39, 2, 529, 48, 25, 181, 2, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 5687, 25, 203, 28, 2, 818, 12, 125, 2, 3077]),\n",
              "         list([2, 111, 748, 4368, 1133, 33782, 24563, 2, 87, 1551, 1262, 2, 31, 318, 9459, 2, 2, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 2, 17, 12, 575, 220, 2507, 17, 2, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 2, 438, 21, 27, 10044, 589, 2, 22, 107, 20123, 19550, 997, 1638, 2, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 2, 19353, 98, 31, 2122, 33, 2, 58, 14, 3808, 1638, 2, 2, 365, 2, 2789, 3761, 356, 346, 2, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 2, 58, 54, 1270, 431, 748, 2, 32, 2580, 16, 11, 94, 19469, 10, 10, 2, 993, 45222, 2, 2, 1766, 2634, 2164, 24563, 2, 847, 2, 1450, 121, 31, 2, 27, 86, 2663, 10760, 16, 2, 465, 993, 2006, 30995, 573, 17, 61862, 42, 2, 17345, 37, 473, 2, 711, 2, 8869, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 2, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 2, 1330, 10104, 146, 655, 2212, 2, 258, 12, 184, 10104, 546, 2, 849, 10333, 2, 2, 22, 1436, 18, 631, 1386, 797, 2, 2, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 2, 12141, 11, 661, 2, 339, 17863, 2, 2455, 11434, 2, 2, 1962, 10, 10, 263, 787, 2, 270, 11, 2, 9466, 2, 61862, 48414, 121, 2, 5437, 26, 4434, 19, 68, 1372, 2, 28, 446, 2, 318, 7149, 2, 67, 51, 36, 70, 81, 2, 4392, 2294, 36, 1197, 2, 68411, 25399, 18, 2, 711, 2, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 2, 2399, 17, 2, 12397, 428, 14657, 232, 11, 2, 8014, 37, 272, 40, 2708, 247, 30, 656, 2, 13182, 54, 25399, 3292, 98, 2, 2840, 40, 558, 37, 6093, 98, 2, 17345, 1197, 15, 14, 2, 57, 4893, 2, 4659, 2, 275, 711, 7937, 25399, 3292, 98, 2, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 2, 17345, 2378, 90, 19, 2, 73284, 2, 36744, 1810, 77553, 2, 4770, 3183, 930, 2, 508, 90, 2, 1317, 2, 2, 48414, 17, 15454, 3965, 1853, 2, 1494, 2, 4468, 189, 2, 31036, 6287, 5774, 2, 4770, 2, 95, 271, 23, 2, 7742, 6063, 21627, 5437, 33, 1526, 2, 425, 3155, 33697, 4535, 1636, 2, 2, 4669, 11966, 469, 2, 4552, 54, 2, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 2, 17303, 68, 1830, 19, 6571, 14605, 2, 1515, 2, 263, 65, 2132, 34, 2, 5680, 7489, 43, 159, 29, 2, 4706, 2, 387, 73, 195, 584, 10, 10, 1069, 2, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 2, 1069, 2, 192, 15, 12, 16, 93, 34, 2, 1766, 28228, 33, 2, 5673, 2, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 2, 819, 2, 22, 1407, 17, 2, 14967, 787, 2, 2460, 19569, 61862, 100, 30, 2, 3737, 3617, 3169, 2321, 42, 1898, 11, 2, 3814, 42, 101, 704, 2, 101, 999, 15, 1625, 94, 2926, 180, 2, 2, 9101, 34, 15205, 45, 2, 1429, 22, 60, 2, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 2, 57, 975]),\n",
              "         ...,\n",
              "         list([2, 13, 1408, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 2, 1492, 910, 769, 2290, 2515, 395, 4257, 2, 1454, 11, 119, 16946, 89, 1036, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2280, 284, 1842, 60664, 37, 315, 2, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2960, 2, 743, 46, 1028, 2, 3531, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 28739, 2, 2, 1861, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 2, 2302, 2, 470]),\n",
              "         list([2, 2, 52, 7465, 430, 22, 2, 220, 2594, 2, 28, 24357, 519, 3227, 2, 769, 15, 47, 2, 3482, 4067, 2, 114, 2, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 2, 2, 364, 350, 2, 184, 5586, 2, 133, 1810, 11, 5417, 13226, 21, 2, 7298, 42657, 570, 50, 2005, 2643, 2, 2, 1249, 17, 2, 25194, 27803, 21, 17, 2, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 1078, 19, 2, 78, 173, 2, 27, 20067, 5698, 3406, 718, 21264, 2, 2, 6907, 17, 210, 2, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 14274, 53, 40, 35, 390, 2, 11, 2, 3567, 2, 2, 314, 74, 2, 792, 22, 16261, 19, 714, 727, 5205, 382, 2, 91, 6533, 439, 19, 14, 20, 2, 1441, 5805, 1118, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBDAFt0FJDJ3",
        "outputId": "1c7163f4-4acc-4cea-faff-9589f30f27fe"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n",
        "imdb.load_data(path=\"/content/imdb.npz\", maxlen=500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 13, 1228, 119, 14, 552, 7, 20, 190, 14, 58, 13, 258, 546, 1786, 8, 1968, 4, 268, 237, 13, 191, 81, 15, 13, 80, 43, 3824, 44, 12, 14, 16, 427, 3192, 4, 183, 15, 593, 19, 4, 351, 362, 26, 55, 646, 21, 4, 1239, 84, 26, 1557, 3755, 13, 244, 6, 2071, 132, 184, 194, 5, 13, 70, 4478, 546, 73, 190, 13, 62, 24, 81, 320, 4, 538, 4, 117, 250, 127, 11, 14, 20, 82, 4, 452, 11, 14, 20, 9, 8654, 19, 41, 476, 8, 4, 213, 7, 9185, 13, 657, 13, 286, 38, 1612, 44, 41, 5, 41, 1729, 88, 13, 62, 28, 900, 510, 4, 509, 51, 6, 612, 59, 16, 193, 61, 4666, 5, 702, 930, 143, 285, 25, 67, 41, 81, 366, 4, 130, 82, 9, 259, 334, 397, 1195, 7, 149, 102, 15, 26, 814, 38, 465, 1627, 31, 70, 983, 67, 51, 9, 112, 814, 17, 35, 311, 75, 26, 11649, 574, 19, 4, 1729, 23, 4, 268, 38, 95, 138, 4, 609, 191, 75, 28, 314, 1772]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 0, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI-Nr897LorW",
        "outputId": "969efca9-ca7e-449a-cfed-f222213ab10a"
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "\n",
        " imdb.load_data(path=\"/content/imdb.npz\", start_char=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gkaFf6MJDJ9",
        "outputId": "a6697aab-6106-45b3-be24-f33d2f00432b"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n",
        "index_from = 3\n",
        "\n",
        "imdb_word_index = {key: value+index_from for key, value in imdb_word_index.items()}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huCi_QIzJDKL",
        "outputId": "5eb7a871-9dab-45bc-9161-6ad2c4d5dcaf"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n",
        "print(\"Fuck: {}\".format(imdb_word_index[\"fuck\"]))\n",
        "print(\"The: {}\".format(imdb_word_index[\"the\"]))\n",
        "print(\"is: {}\".format(imdb_word_index[\"is\"]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fuck: 54485\n",
            "The: 4\n",
            "is: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "p7UkZwHiJDKU",
        "outputId": "f03360e7-ef33-4099-ccb4-ef3c832dc42a"
      },
      "source": [
        "# View an input sentence\n",
        "\n",
        "inv_imdb_word_index = {value:key for key,value in imdb_word_index.items()}\n",
        "\n",
        "\" \".join([inv_imdb_word_index[word] for word in x_train[0] if word > index_from])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq2ID8wRJDKX",
        "outputId": "0a123fe4-830a-4218-9d0d-c16c8f28401b"
      },
      "source": [
        "# Get the sentiment value\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV"
      },
      "source": [
        "# Load the imdb data set\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWULtJ7CJDKe",
        "outputId": "06c72309-f94b-48e6-b814-7fb4a6798bbb"
      },
      "source": [
        "# Inspect the input data shape.\n",
        "# Length of Each Review\n",
        "\n",
        "[len(x) for x in x_train[:10]]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[218, 189, 141, 550, 147, 43, 123, 562, 233, 130]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n",
        "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding=\"post\", truncating=\"post\", value=0.0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNPiMGwDJDKk",
        "outputId": "733dc254-1e85-4046-cd7b-69e794976e21"
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo"
      },
      "source": [
        "# Import numpy \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8LjX9QaJDKr",
        "outputId": "bc072bf0-b613-49be-bec9-c01c0103092e"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "\n",
        "padded_x_train = np.expand_dims(padded_x_train, axis=-1)\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt"
      },
      "source": [
        "# Create a Masking layer \n",
        "\n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype=tf.float32)\n",
        "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "MuStn9s0JDK0",
        "outputId": "f086ad48-9172-4a99-ce72-fc46da5d2ca6"
      },
      "source": [
        "# Look at the dataset\n",
        "\n",
        "tf_x_train._keras_mask"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b771af6b4144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Look at the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O54DVLx4JDK7",
        "outputId": "9e0d5e89-2735-47b2-ae0c-9ee42b28eb2a"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n",
        "masked_x_train._keras_mask"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLdAppqgMaqP"
      },
      "source": [
        "from tensorflow.keras import layers, models, callbacks\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=501, output_dim=16, mask_zero=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf3B6HamJDLN",
        "outputId": "4e3ea78e-3a65-4fd1-a04c-f52a42fbdf4c"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "\n",
        "sequences_idx = tf.random.uniform(shape=(5, 10, ), minval=1, maxval=500, dtype=tf.int32)\n",
        "\n",
        "sequence_emd = embedding_layer(sequences_idx)\n",
        "sequence_emd.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 10, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ualmsaPpJDLV",
        "outputId": "3320ce53-2f29-4f9f-d6f2-609e92fa1bd1"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "\n",
        "embedding_layer.get_weights()[0].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wadlt3AJDLX",
        "outputId": "eb895d2a-51f7-427f-979f-14cd999ddc96"
      },
      "source": [
        "# Get the embedding for the 4th index\n",
        "\n",
        "sequence_emd[0, 4]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
              "array([-0.04794912, -0.02267637,  0.00813713,  0.04214254,  0.00555458,\n",
              "       -0.02797263,  0.04208437,  0.01627687, -0.02544979,  0.0433146 ,\n",
              "        0.02657041,  0.00683339, -0.04080252,  0.03867007,  0.04649437,\n",
              "        0.04983782], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDFlyHQUOAaC",
        "outputId": "34eed82b-4bb7-4969-aeac-eab1512ed197"
      },
      "source": [
        "# Get the embedding corrosponding to 4\n",
        "\n",
        "embedding_layer(tf.constant([[4]]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 16), dtype=float32, numpy=\n",
              "array([[[ 0.03563842,  0.00201718,  0.0038924 , -0.03688633,\n",
              "          0.04780615,  0.04300157, -0.04038479,  0.03331479,\n",
              "         -0.02109056,  0.02576854,  0.01062188, -0.04384543,\n",
              "          0.04442978,  0.04721821, -0.02587217,  0.04008048]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hc1zx6A-H6R",
        "outputId": "c3424357-3a86-4ceb-bf6b-ae8f1f1c8ccd"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "sequences_idx = tf.random.uniform(shape=(5, 10, ), minval=1, maxval=500, dtype=tf.int32)\n",
        "\n",
        "sequence_emd = embedding_layer(sequences_idx)\n",
        "sequence_emd._keras_mask"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv"
      },
      "source": [
        "# Get the word index\n",
        "\n",
        "word_index = get_imdb_word_index()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_word_index = {value:key for key,value in word_index.items()}"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "cquirCA8BS99",
        "outputId": "b42ce96a-c15d-46bd-9556-a76ab9ff93f9"
      },
      "source": [
        "# View the first dataset example sentence\n",
        "\n",
        "\" \".join([inv_word_index[x] for x in x_train[0] if x > 2 ])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert is an amazing actor and now the same being director father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also to the two little boy's that played the of norman and paul they were just brilliant children are often left out of the list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPUfv9kjJDL1",
        "outputId": "594b4c20-5607-48e5-a411-07671d28aec0"
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_token = max(inv_word_index.keys())\n",
        "max_token"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dims = 16"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(None,)))\n",
        "model.add(layers.Embedding(input_dim=max_token+1, output_dim=embedding_dims, mask_zero=False))\n",
        "model.add(layers.GlobalAveragePooling1D())\n",
        "model.add(layers.Dense(units=1, activation=\"relu\"))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOSIvhRtQGtN",
        "outputId": "8ccde5b1-58a5-4f33-faf3-0867b6804d92"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "inputs = layers.Input(shape=(None,))\n",
        "h = layers.Embedding(input_dim=max_token+1, output_dim=embedding_dims, mask_zero=False)(inputs)\n",
        "h = layers.GlobalAveragePooling1D()(h)\n",
        "outputs = layers.Dense(units=1, activation=\"relu\")(h)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf6oaEvTCKxV",
        "outputId": "3a7f4874-5c49-4e01-ca3b-16aecd5c0dda"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvR-O7wGJDMC",
        "outputId": "f2e6f0c8-b6b3-460c-a9f8-5f1a293b59a8"
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "hisotry = model.fit(x_train, y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=50, \n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 2.0240 - accuracy: 0.5252 - val_loss: 0.6863 - val_accuracy: 0.6023\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6802 - accuracy: 0.6608 - val_loss: 0.6735 - val_accuracy: 0.8165\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6632 - accuracy: 0.7964 - val_loss: 0.6520 - val_accuracy: 0.7898\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6325 - accuracy: 0.7934 - val_loss: 0.6132 - val_accuracy: 0.7430\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5779 - accuracy: 0.8088 - val_loss: 0.5486 - val_accuracy: 0.8088\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5081 - accuracy: 0.8298 - val_loss: 0.4935 - val_accuracy: 0.8382\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4494 - accuracy: 0.8534 - val_loss: 0.4526 - val_accuracy: 0.8524\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4073 - accuracy: 0.8604 - val_loss: 0.4278 - val_accuracy: 0.8615\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3723 - accuracy: 0.8797 - val_loss: 0.4095 - val_accuracy: 0.8712\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3533 - accuracy: 0.8826 - val_loss: 0.4037 - val_accuracy: 0.8751\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3362 - accuracy: 0.8890 - val_loss: 0.3976 - val_accuracy: 0.8764\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3648 - accuracy: 0.8844 - val_loss: 0.4682 - val_accuracy: 0.8336\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3091 - accuracy: 0.8987 - val_loss: 0.4021 - val_accuracy: 0.8781\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3039 - accuracy: 0.9022 - val_loss: 0.4027 - val_accuracy: 0.8760\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2924 - accuracy: 0.9028 - val_loss: 0.3959 - val_accuracy: 0.8830\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3201 - accuracy: 0.9011 - val_loss: 0.3948 - val_accuracy: 0.8839\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2765 - accuracy: 0.9099 - val_loss: 0.3915 - val_accuracy: 0.8854\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2703 - accuracy: 0.9109 - val_loss: 0.3913 - val_accuracy: 0.8857\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2656 - accuracy: 0.9129 - val_loss: 0.3972 - val_accuracy: 0.8839\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2585 - accuracy: 0.9155 - val_loss: 0.3940 - val_accuracy: 0.8832\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2661 - accuracy: 0.9124 - val_loss: 0.3910 - val_accuracy: 0.8884\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2556 - accuracy: 0.9160 - val_loss: 0.3919 - val_accuracy: 0.8885\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2418 - accuracy: 0.9213 - val_loss: 0.3948 - val_accuracy: 0.8877\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2530 - accuracy: 0.9184 - val_loss: 0.4070 - val_accuracy: 0.8866\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2333 - accuracy: 0.9234 - val_loss: 0.4056 - val_accuracy: 0.8878\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2342 - accuracy: 0.9228 - val_loss: 0.4120 - val_accuracy: 0.8885\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4636 - accuracy: 0.8970 - val_loss: 0.4429 - val_accuracy: 0.8832\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2244 - accuracy: 0.9246 - val_loss: 0.4203 - val_accuracy: 0.8874\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2303 - accuracy: 0.9225 - val_loss: 0.4172 - val_accuracy: 0.8898\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2134 - accuracy: 0.9309 - val_loss: 0.4184 - val_accuracy: 0.8899\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2102 - accuracy: 0.9306 - val_loss: 0.4244 - val_accuracy: 0.8900\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2074 - accuracy: 0.9308 - val_loss: 0.4284 - val_accuracy: 0.8899\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2057 - accuracy: 0.9322 - val_loss: 0.4348 - val_accuracy: 0.8908\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2104 - accuracy: 0.9316 - val_loss: 0.4450 - val_accuracy: 0.8888\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1982 - accuracy: 0.9348 - val_loss: 0.4512 - val_accuracy: 0.8906\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2534 - accuracy: 0.9274 - val_loss: 0.4518 - val_accuracy: 0.8904\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1967 - accuracy: 0.9356 - val_loss: 0.4533 - val_accuracy: 0.8906\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1861 - accuracy: 0.9384 - val_loss: 0.4626 - val_accuracy: 0.8905\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1849 - accuracy: 0.9382 - val_loss: 0.4714 - val_accuracy: 0.8903\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1816 - accuracy: 0.9399 - val_loss: 0.4836 - val_accuracy: 0.8897\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2356 - accuracy: 0.9342 - val_loss: 0.4833 - val_accuracy: 0.8893\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2765 - accuracy: 0.9310 - val_loss: 0.4841 - val_accuracy: 0.8879\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1733 - accuracy: 0.9428 - val_loss: 0.4915 - val_accuracy: 0.8892\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1709 - accuracy: 0.9440 - val_loss: 0.4990 - val_accuracy: 0.8894\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1686 - accuracy: 0.9446 - val_loss: 0.5061 - val_accuracy: 0.8888\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1664 - accuracy: 0.9446 - val_loss: 0.5127 - val_accuracy: 0.8886\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1650 - accuracy: 0.9461 - val_loss: 0.5316 - val_accuracy: 0.8864\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1618 - accuracy: 0.9462 - val_loss: 0.5518 - val_accuracy: 0.8843\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1603 - accuracy: 0.9479 - val_loss: 0.5458 - val_accuracy: 0.8874\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1853 - accuracy: 0.9452 - val_loss: 0.5558 - val_accuracy: 0.8873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Ind0d_gvJDMG",
        "outputId": "5315d090-a8da-478d-b160-f53526434ea4"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = hisotry.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAFRCAYAAAC2QXZWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xc1Znw8d+ZGbVR77IsuclF7hUbY+OCjemGhBowzeFNwHkDmzfZ3dCWJZSwCc4mIRBIM7DZbLyEEjCOccHGDWNjucm23Lt6L6MyM/e8f9zRSKNijawuP9/PZzxz79zy3Jnj0X3uKVdprTVCCCGEEEIIcZmx9HQAQgghhBBCCNETJBkSQgghhBBCXJYkGRJCCCGEEEJcliQZEkIIIYQQQlyWJBkSQgghhBBCXJYkGRJCCCGEEEJcliQZEkKILrBp0yaUUpw/f75d6yml+POf/9xFUXWf7jiO06dPo5Ri69at7drvvHnzeOSRRzq8/7fffhubzdbh7QghhOg5kgwJIS5rSqmLPoYMGXJJ273qqqvIyckhOTm5Xevl5ORwxx13XNI+Rdd8fufPn0cpxaZNm3zm33333Vy4cKFT9yWEEKJ7ySUtIcRlLScnx/t6+/bt3H777WRkZDBgwAAArFarz/J1dXUEBga2ud3AwECSkpLaHc+lrCMadOfnFxISQkhISLftrzdyOp0EBAT0dBhCCHHJpGZICHFZS0pK8j5iYmIAiI+P985LSEjg17/+Nffeey+RkZHcf//9ADz99NOMHj0au91Oamoqjz76KGVlZd7tNm0mVz+9bt065syZg91uZ8yYMfzjH//wiadpMy+lFG+88Qb3338/4eHhpKSk8NOf/tRnnaKiIu68805CQ0NJTEzk2Wef5cEHH2ThwoUXPfa2jqG+Gdi2bduYMmUKdrudqVOnsmvXLp/tbNy4kQkTJhAcHMyECRPYuHHjRfd77NgxlFJs377dZ/5XX32FUopjx44B8Ktf/YpJkyYRFhZGUlIS99xzj0/y2pKmn9+ZM2e4/vrrCQkJITU1lddee63ZOn/5y1+YMWMGkZGRxMXFcdNNN3H06FHv+6mpqQDMnz/fp7awpWZyq1evZurUqQQFBZGQkMCyZcuoqqryvv/QQw+xcOFCfve73zF48GAiIiJYvHgxeXl5Fz2utmIEyM/P5+GHHyYxMZHg4GBGjRrFn/70J+/7J06c4I477iAmJga73c6ECRNYtWpVq8fStEasvgx/+umnzJ49m+DgYP7whz9QUlLCkiVLGDRoECEhIYwaNYrly5ejtfbZ3sqVK5k6dSrBwcHExsZyww03UFJSwttvv01UVBQOh8Nn+Z/85CeMGDGi2XaEEKIzSTIkhBBteP7557nqqqvIyMjgxRdfBMxagd/97nccOnSIt99+m02bNvH444+3ua0f/ehHPPXUU+zbt48ZM2Zw9913U1JS0ub+58yZw969e3nyySd56qmn2LBhg/f9hx9+mH379rFq1So+//xzzp8/z0cffdRmLP4cg2EYPPnkk/zqV78iIyODhIQE7rrrLlwuFwDZ2dncfPPNTJ06lYyMDJYvX84TTzxx0f2OGDGCmTNn8l//9V8+89955x1mzpzJiBEjvPNeffVVDhw4wIcffsjZs2e555572jyuelprvvGNb1BUVMSmTZv45JNP+Pjjj8nIyPBZrra2lmeeeYaMjAzWrVuH1Wrlpptuoq6uDsC7/Pvvv09OTk6zZLDe/v37Wbx4MXPmzGHfvn288847rFq1ikcffdRnuV27drFx40Y+/fRTPvvsMw4cOMCPfvSjix5LWzFWV1czd+5c9u3bx3//939z6NAhXnvtNex2OwC5ublcddVVlJaW8vHHH3PgwAFeeOEFLJb2nwb88Ic/5F//9V85fPgwt9xyC7W1tYwbN46PPvqIQ4cO8eyzz/Lcc8/x9ttve9dZsWIFS5Ys4bbbbiMjI4ONGzdy/fXX43a7ufvuu1FK8d5773mXNwyDP/3pTzzyyCMopdodoxBC+E0LIYTQWmu9ceNGDehz58555wF66dKlba77wQcf6MDAQO12u1vcVv30+++/710nNzdXA3rNmjU++/uv//ovn+nvf//7PvtKT0/XP/7xj7XWWh89elQDev369d736+rqdEpKil6wYEF7Dr/ZMaxYsUIDevfu3d5lduzYoQGdlZWltdb66aef1oMGDdJOp9O7zCeffNLsOJr67W9/q6Ojo3Vtba3WWuva2lodExOj33zzzVbXycjI0IA+f/681lrrU6dOaUBv2bLFu0zj/a5bt04D+siRI9738/PzdXBwsP72t7/d6n6Kioo0oLdu3aq11vrcuXMa0Bs3bvRZbsWKFdpqtXqnlyxZoq+44gqfZT766COtlNKnT5/WWmv94IMP6vj4eF1TU+Nd5pVXXtFJSUmtxuNPjH/4wx90UFCQT9lt7JlnntGJiYm6srKyxfebHovWzY+7vgy/++67bcb3+OOP64ULF3qnU1NT9fe+971Wl//+97+vZ82a5Z1es2aNDggI0Hl5eW3uSwghOkJqhoQQog3Tp09vNu+DDz5gzpw5JCcnExYWxn333UddXR25ubkX3dakSZO8rxMTE7FarW02kWq8DkBycrJ3nUOHDgFw5ZVXet8PCAhg2rRpFz8oP49BKcXEiRN99g347H/69Ok+Taxmz57d5r7vvvtuHA6Ht5nWqlWrqKqq4u677/Yus2nTJq677jpSU1MJDw/3bvfMmTNtbr8+tri4OEaOHOmdFx8fz6hRo3yW27t3L9/4xjcYOnQo4eHhDBo0qF37qXfw4EHmzJnjM2/u3Llorb3fE0B6ejpBQUHe6cbfZ2vainH37t2MGTOGlJSUFtffvXs3V111FaGhoe06ppY0/f9gGAavvPIKkyZNIi4ujrCwMN58801vbPn5+Zw7d45Fixa1us3vfve7bNu2jcOHDwPw+9//nsWLF5OQkNDheIUQ4mIkGRJCiDY0PYH86quvuPPOO5kzZw4ffvghGRkZvPnmmwDeZkutaWnwBcMw2rWOUqrZOu1tSuTvMVgsFp9BJOr301bMbYmOjuaWW27h3XffBeDdd99l8eLFREVFAXD27FluvPFGhgwZwl//+le+/vprPv7442bxdZTD4WDRokUopVixYgU7d+5k165dKKU6dT+NtfR96ov0i+mOGFtqLud0Oltctun/h+XLl/PTn/6Uxx9/nHXr1rF3714eeeSRdsU2duxYZs+eze9//3vy8/P5+OOP+c53vtO+gxBCiEsgyZAQQrTT1q1biYuL48UXX2TGjBmMHDmy3fcT6ixjxowB4Msvv/TOc7lc7N69+6LrddYxjBkzhp07d+J2u73ztm3b5te6Dz74IKtXr+bIkSOsXr2aBx54wPverl27qK6u5pe//CWzZs1i1KhRbdaetBRbYWGhd0AGgMLCQo4cOeKdPnz4MAUFBbz00kvMmzeP0aNHU1JS4pOc1CcvjY+xJWPHjmXz5s0+87744guUUowdO7ZdsTfmT4xTp07l0KFDrX6HU6dOZfv27T6DOTSWkJCA2+32+Yyb9q1qzebNm7n++utZunQpkydPZvjw4T6feUJCAikpKaxdu/ai2/nud7/Lu+++y+9+9zsGDhzItdde69f+hRCiIyQZEkKIdho1ahQFBQX88Y9/5OTJk7z77ru88cYbPRLLiBEjuOWWW/je977HF198waFDh/jud79LeXn5RWuLOusYHnvsMQoKCvjOd77D4cOH2bBhA08//bRf615//fVER0dzzz33EB0dzfXXX+9zXEopli9fzqlTp/joo4/4yU9+0q7YFixYwMSJE1myZAk7d+5k79693HfffT5DQQ8ePJigoCBee+01Tpw4wYYNG3jiiSd8Prv6pl9r164lNze31QEv/vmf/5mMjAx+8IMfkJWVxZo1a/j+97/Pfffd523Wdin8ifFb3/oWgwcPZvHixaxfv55Tp06xYcMGVq5cCcCyZcswDINbb72Vbdu2cerUKVatWuUdzXD69OmEh4fz4x//mGPHjrFmzRq/P+9Ro0axadMmNm7cyNGjR3nmmWf46quvfJZ57rnneOutt3jhhRc4fPgwBw8e5De/+Q2FhYXeZervD/XCCy/IwAlCiG4jyZAQQrTTzTffzNNPP81TTz3F+PHj+etf/8rPf/7zHotnxYoVjBs3jhtuuIF58+Z5r6oHBwe3uk5nHcPAgQP55JNP2LlzJ5MmTeKJJ57gF7/4hV/r2mw27r33Xvbu3cu9997r0+9owoQJvPbaa7z11luMGTOGV199lV/+8pftik0pxUcffURkZCRz5szh5ptv5sYbb2TKlCneZeLi4vjzn//MunXrGDt2LD/60Y949dVXfZqNWSwWXn/9df73f/+XlJQUJk+e3OL+JkyYwMcff8zmzZuZOHEi999/PzfddJO3+eGl8idGu93OF198wbhx47jnnnsYPXo03/ve96iurgZgwIABbN26lfDwcG688UbGjh3L008/7a1diomJ4X/+53/YsWMHEyZM4IUXXuBnP/uZX/E9++yzzJ07l1tvvZWZM2dSUlLSbFTCRx55hLfffpu//e1vTJo0iTlz5vCPf/zD5zsPDg7m/vvvxzAMli5d2qHPTAgh/KX0xRoqCyGE6HPcbjfp6eksXryY5cuX93Q4Qvjtrrvuwul08uGHH/Z0KEKIy4St7UWEEEL0Zps3byY/P5/JkydTUVHBf/7nf3L69Gkeeuihng5NCL+UlJSwc+dOPvzwQ597aAkhRFfrlmTojTfeICMjg8jIyBavUmqtWbFiBXv27CEoKIhly5YxbNiw7ghNCCH6PLfbzYsvvsjx48cJCAhg3LhxbNy4kfHjx/d0aEL4ZfLkyRQVFfEv//IvzYYnF0KIrtQtzeQOHTpEcHAwr7/+eovJUEZGBmvWrOHJJ5/k2LFjvP3227z88stdHZYQQgghhBDiMtYtAyiMGTOGsLCwVt//+uuvmTNnDkopRo4cSVVVVauj9QghhBBCCCFEZ+gVo8kVFxcTFxfnnY6NjaW4uLgHIxJCCCGEEEL0d31uAIX169ezfv16AF555ZUejkYIIYQQQgjRV/WKZCgmJsbnxmtFRUXExMS0uOzChQtZuHChdzo7O7tTY4mLi/OJRYj2kjIkOkrKkOgoKUOio6QMiY7qTWUoOTm51fd6RTO5adOmsXnzZrTWHD16FLvdTnR0dE+HJYQQQgghhOjHuqVm6Je//CWHDh2ioqKCRx99lLvuuguXywXAokWLmDx5MhkZGTz++OMEBgaybNmy7ghLCCGEEEIIcRnrlmTon/7pny76vlKKRx55pDtCEUIIIYQQQgiglzSTE0IIIYQQQojuJsmQEEIIIYQQ4rIkyZAQQgghhBDisiTJkBBCCCGEEOKyJMmQEEIIIYQQ4rIkyZAQQgghhBDisiTJkBBCCCGEEOKyJMmQEEIIIYQQwoc+kYWx+j30iayeDqVLdctNV4UQQgghhOhN9Iks9JEDqFHjUWnpXb5ee9fVWoPbBS4n+thhOHYQhqWjhqQ1Wsi7cJMZDS/1meNw/DCkDkUlpYCzFpxOcNahnU6faTzTOj8Xdm0Gw0BbrDB7ISp5MASHoIJDwPuwN3odgrJavcdZ9cVJdMqwdn9G3U2SISGEEEII4dWXTmSNgxmw5ysYOBiVmAxut5lAuF1ol8vz2jPP1fBa5+fCl5+D4TZP9qdchYqMAsMAbZjP9Y9G07q8FI4eBG2glQWGp0NouBmM1r7BNZ7WGqoq4dQR0BqtFCSlgM1mxuVyNnp2mkmJy9niMesW5/rH73UtFvOYAQw3bP6MFtKt5gICISAAHFVUKgW2ACw/fLFXlyNJhoQQQgghulB31SS0th5DRniu+nsedXXg8jx7awTq0M469IUz8NkHVBoGWG2opT9ATbgCFRTU3sPudNowIOc8+mQWnMhCZ+2HovyG9y91w4Yb9nyJDgwCpcxEoPFDNXp2VJrJkRkQ5GVDRHTDtlT9s2oyAygvaUiQ6mt9EgaYn7MtAAJsYAtoeASYz/r4YcjMMI9QKZg4HTV+Ks12qhrtq/4zydwNGTu866or56FmXmNuOyCw0cMzbfO8PnUUY/kzZoxWG+qJ51DJg6Cm2ueha6qhxgG1jeYdzYRTx7zHqI8ckGRICCGEEKKpjiQJl8o4fhiy9qNGT+yWfRrHDqL/89/A5UJbrXDdN1HhUc1PIJucZFJbbdYk1NYA9Sf6CizK90Rb1T83eq21meDQsVoEXE70735mbsMeCtFxEBWDioo1X0d7Xnumdd4FOJrZad+ndlTCySPok0fQJ47AqaNQXWW+GRoOYRENCyuFmr0INWuBWdti9TxsNrBam7wOQJ8+Zn4vnpN9f2sv9IksnyTBsuwpv4+12bpLf+D/Po8caFjv+tv932fyIIwDuxuSmrk3+LduWjqWH77Y/P9neKTPYs3Tr+bHqUaN9yvWnqK0blqn17dkZ2d36vbi4uIoLCzs1G2Ky4uUIdFRUoZER+gTWdjPn8TRziZOnVV7wdCR5klQfTMf78PVqPmPC332JPqDt81mS1Yr6tYlqOTUlq/GW1TDtGeevnAaThyBxIGo6Bi0owqqHebJsue1rq7yTHvmV5Z7kwsAUoehBqdBfBIqYYB5lT5+ACrE3q7jB8z9511A55w3n3PPQ+4FyD3f0NyoKasVgkJ8+lx4+14EhZjJxckjnoUVjByHGj4a0J4aBm1mO41fo9Enj5h9ROqNnogaO8WnNkAFBrZQMxCEzj6L/uMvzO/QYjGTt4BAKC1GlxZBSRGUFkF5afNmYfWUgpShEBtvfpb2MAgJhRA72ENRIaFmcmX3zAsJQ2ef9dTOBKLKy8xjyDnn2Z4FBg5CDUuHYaNQaaMgcSCcPOKbXLSzOVZv7zPU0/vsiEv9HeoqycnJrb4nyVATchIiOkrKkOgoKUPCH9owzCZCufUn3ufRp47CuVMNCwUEgsVqJhP1tQjK0qQ2QZkJSVVFw3ph4WANwHvS3bTvg7dnNmaSU1vdxUfbDkp5TrBDzYfdfK1CQtH52Y2SCyAm3kzQykt9txEeCQkDUPH1CZKZLOmqSjiyHyKjzf3kXkDXJzxlJQ3rW60Qn2T2CQkKhq+3mU2xrDbUI/8PNXKcmfTYAlAtNG2q16wm4VJrLy4hSWjrRFa7XGazL09yZGzbAAe+blggNsH8Hhonqf4KtsOIMahho8z9Dx2BCm45Qe2JE33hn970t0ySoXboTV+c6JukDImO6itlqKeuNvalq6NGxpdwcA+kjTKvagcGQWCg+RwQ2OqJsE9NS8rQRjUNZm1Dfe1DfVMowGw2FBQMxQUN84aPRg0Z4dtPQRveGgQMM7HRZ0/A6eMN6w0ZjkodZr5WjRKpFqb1mRO+CUb6BNToiT59HsyHp1+E57XOz0b/9Q8NNUP3PYoaOLjFTuto7TNff70VvXOzOV8p1PybUNd9w0x+goJRlpbvHNJakqBrHFCQB/k56PwcKGh4pqSo9RoQexgMSEElDYSkhmfiklA2m89++1JNArT/d6itBEwbhtn8z1tzZz7ragf6662wf5e5oLKgbrsPy413tjtm0bv0pr9lF0uGpM+QEEIIv2mtwVGJPrAb/c6vwe1GW62oux4xm640HmrVz5P9+hMm7XJCeZl5tbmsFF1eYl5tLy9Bl5WaJ/8XzpjLgnnVOSDQ03TK2qTTs9W3uVVdrZlIaI0OCMDyw5e6NCHShXkYf3mr4Ur55jUt990IDGr08CRJbjdknzVjbbq8UhCXaJ54j5noOQFPMZ/DI5qfkN7x8KXVJNzznUvvB3HbEr/WVaMnolOGXtoJe3gkOuPLhj4J0+egYuLb3mcr/SBUsB1Sh5pDDzc9PmcdFOahV/8NvWMT3o7oN9yBum3JRWt2Gu/3Usvbpa7bkX1eitY+W+/7FktD07jYRvMBnTAA4/C+PtPHRPQvUjPURG/KYkXfJGVIdERPtLPW9aMyDRqGio6F0hJ0WTGUFkOZ53VZiXe6teFem7Fafe9BEeJ57XLB0UzzKr9SZnOaGgdUVrS8ndBwiIgy91uQ2zB/6EhU6tBGQ+C6G4a/bfQaw4D8bMjPaVh3yAgs3/lnVHzSpX9wLdClRehP30NvWdtQswHmcU6dhRozyUzM6mrNkby8r82HdtaZiVDj4xw9Ecuc68wah8Rks//GxWLo4T5DfaGW8FL315GmZ31Nd/8tk+Zu/U9vOh+SZnLt0Ju+ONE3SRnqXbr7BE+73eijByBrv9k5O3Fgw4hRtTXomhqfaWprzESgpgZdUmiOlqS1WZsxZqLZZyHE3ugRal7FDrGbfSGCzXk6+wwcOwRpo82mOo5KcyQqR6U5IlNVw7Q5r8qcLi2CwrzWD8geCpExEBmNijKfiYxB11bDp+81NHG64yFUbDy6un40LIfZT8DzWld7Rseqdpj7qyxv2MeAVNSocebwtJFRqIhocz8R0RARhQoI8H4fl3oy6l3X5fL0mzFH3FLT56JuvAM1INWv7bS6/fJS9Jr30Zv+AYYbNftaGDsF/ftXu72/B8jvUFe5nE7YpQyJjupNZUiSoXboTV+c6JukDPUexvHD6F94ToCtVtSt96LiB6Dd7kY35mv0bLi9N+XThXnw1RfmPIsFRk80+2M0vprvrGt+hd/t8j9Ai6VhJKmgYDOBKC1ueN8eZp60V1e1PhpVewWHmNu1h0FomNlx3Dtik0JdcTVq/o0NCVBg6/cW6Uhfho4kNZ0y4llsPPqzj9Cb15jf45SZWG68EzUore0NNd5mVSV67YfoDZ9AXR1q5nzUzXd7a5z6Sn8PIZqSMiQ6qjeVIUmG2qE3fXGib5Iy1LquuqqqDcPsNJ5zzhyeNdvzfO5U+5ITHwqfO3TYwyAqxuyjEhTU0AG+SZ8Pffo4HN6Pt1/B9DnmDe7qE56gYE/TseBmI0m12rlbazPhqvGMyFTt8D50jQO9e3ujUZwUTLzCTGpC65OecE8CFIqyWn0/ux5q+tNbrrDrijL0+k/QG1eZn+n4aVhuuqvNmHS1A73hY/Tav0N1lfl5L/6W2X+nF5DfIdFRUoZER/WmMiTJUDv0pi9O9E39uQxpw22O/pO132ySNTjNM/qTNmtQtGG+1s1Hg9LZ59B//3OjZlUPowYP973ztc8dsG0oS8OJu7dfS9JAVECgb9KTe9733iGR0TAg1UwA9u1sGNJ2yTLU4GGem/FZfZ8tVt95Te6+3ZuGtO2KffaGxKQnaUcleuNq9Pq/m32X0ieYo1mlT/BNWGtr0Zs+Ra9531xu0gwst96LShnag9E3159/h0T3kDIkOqo3lSFJhtqhN31xom/qK2VIO53oHRvh2CF0bAIqPMLTn6TK7FNSVeUzjaPS7P/Rnaw2M0GyWMw4moqMgeRUVPIg83mA5zk03LvI5TCkbWfsU5h0TTV682fotR+ag0WkpaMmzzQHN3BUwa7N5vyxk7HcugQ1dERPh9yivvI7JHovKUOio3pTGZJkqB160xcn+qbeWoa01nDhDPrQXvThvZB1oOVRwYKCvU2qzEcYyjsdhj5z3GySVX9/jxlzUVdc3eTu8KrZXeR19ln0n3/bUDN017fNO74769BOp9lvw1Vn3p3eWf9cC04n+sRhOHXMjE8p1NXXob75gNkMrB/qrWXocqKddeht69Ef/xUqGt2QM3WoOez0yLE9F5wfpAyJjpIyJDqqN5Uhuc+QEH1AV1zZ1yVFZuJzaC/68L6Gu6wnpcCgYT4jl6kbbkfd8i2fGwW2FqfP/SDm3ejfPUWGjkQnpbR4jG3dpaNpMzB11TX9NhG6VFkF1WTmORiXaCc9PqTb1u1u3XWcKiAQNe9GjMoK9N//grcP2LTZ3ZIIdfQ4T546x7Aw2rVud3y2WmsMDS5D49aarIJqDhVUMzHRzthEOxY/7tnT0XizCqo5kFfFuAQ7oxPsfq/XkX0ezneQme9gXELDev7cn6gj++yvZehy3afoOpIMCdEDtOGGslIoykcX5aOPHYItn5l9a6xWMykZMQbCoyAi0qyd8edO9QMHwZGD6MN70Yf2NowSFh5p3hF+zCTU6ImomPjmCcaEK9pMhKDtG+u1te6l3jzwUvfZn/9o1bkNSqpd7M1x8Luv83AbGouCm9OjSQoLpHG9f/3tO5u2BcitdPKPoyUYGiwKFqdHkxwRhFWB1aKwKIVVgcWisCiwKuWZDxfK6jhdWsPw2BCGxwRjtShsFoXNQsNrz/L18+vLcePPdlRcsPcE2Wlo80TZ8+w0NC63xmXAieIafv91Hi5DY7UolkyIIzki0OyypjVuz7N32miYzqmoY7XnOK0WxWNXJDI5OZSoYBtWS+snpWr0RPTq99p9M0itNdUug705VWTmORgUGURieCA1LoNal0GN96EbTZuvCx1OjhbWoDEvFCSHBxIcYDG/Rd0wrEf9d6k9/2g0NS6DgiqXd904u40gm6VhuSbr1m+hzm1Q6HB758TZrQR6BttQqvkFi/qfIwXUugzyPfsEiA62YlEKtza/R3d98uN53ZL3MosACLQqgmwWglp9thBoUzicBl+dq8DtKbdTkkMJDbBS5zaoc2vPo9Frl0Gdoal2mvNaUj/ievNp5f1OG69qVQ3LN/5eWppuj/oQPKO/+2zHglnhDuqi8Rpa+xynPcBCoNX8/2xRNHrGZ55SUOfSZFfUecvQ4KhAwgKtoBQWzz5Uo9cWz3RlrZuswmrvb8mU5FDi7QHYrIoAiyLA82zzvrYQYDWn86vq+J/9Rbg9/7fvHBtLQliA+Rvg1j6/DS53w+uCKie7LlR69zkh0U5EkPl3THt+9Xz+n3inNeW1bg4XNMQ7LtFOVLDN+xkrmn9WSilKa1xsP1th/pYomD04nPjQwCbfQcP/G4X5wgIUOJxsOFHm3eftY2MZGh1EkNVCsM0s20E2C8FWC0E2RbDN/IwsSnXr3zJDm78l+3MdHMx3MCI2mGExwTSUPN9yWq/xvBPFNeQdq2J0lKVX/v1sTJrJNdGbqvRE31Pf+b0qKRUVGQPFBeiifHOks6J8dHEhFOVDSVH7RjmzWiEsEsIjISISFeMVyyYAACAASURBVB4JEVHoujrYus7clvL8ZTYMcxCCEWNRYyaZN3kcONi8+3cL8XZnP5OmP8j1Jxduz1ViwwC3Nv/IGd755rzjRdUcLaxhcFQQyRGBON3mH0mnYZ701P/BrPPMc7o1+ZV1bPX80bIomDIglIhgG2BuH8+JhvacSBqN/miW17g41OgP5RXJYcSHBRBoVZ6HeXIR0Oh1/fycijrOlNYyMjaYtNiQRklEwx/WxolGfXJhVYqjhdUcKdfE2txEh9gornZR0uhRXNPwurKuk4bb7kb1JxWuXhK6RUFkkJXoEBsxITaiPY+YRtPFp85w6mwuwwYlkTB8COW1bspr3OZzrcvzbD4qat2Ued5zGf79ebVZFMGek6AQmwWH06C4uuH3ITk8gORwz8mW52S3aYJSP32hvI6zZXXe+YMjA0mJDPJZzvu60frnyuo4XVrrnR4SFUhqZJDPyWS9psnYhfJan30OjQ4iLSbYW+brE+j6sm6zKKxKcTDfwZ6cKu9J97hEO2kxwdS6DGo9yUytS1PreTanzdcVdW6fk/0Qm4XIYKvP/81AqyLQZiHAogiymSffZ8pqyCqo8R7/+EQ7oxNCGk6Ym504a+/0kcJqDuY39JscmxBCelyIz4WqZgmKgsP51ezPc/jsc0xCw8lh60kqHC6o5oBnXYBxCebFg9YSL63NBOBYUTWHCxoGlRkZG8zQ6GDzd1Y31NAZzZ7N7zO7oqEJdWJYAPF2m7kevr+XjV+XVLsorWlIqO02Czar8v5O+/v/oS0WhTehchmaWlfDdsMCLYQHWWn8jTT+v9I4iS+vcVNa2xBveKCVsCCL9/Nxe47PaPKZ1bp9j6X+N81oVIY6+8TaZmn4zay/QBIZbCXYZiZNQVaLebHAk0AFeZKpIJuFIoeTvx0s9iSacG1aFKGBVqrq3DicBg6nm6o6gyqngcM7z+i0Ywi0Kl5YMKjHEyJpJidEOxmH98OhPZAyxLxfSI0DqqvR3htJmtP1N5bUNdVQXAjZZ6hs9MfTS1nMYZlj41HD0iE2HmLiUbEJ5v1OykrQr73QcPX5/u+homLQ5aVmf4XyMqgoQ1eUQXkpOj8HKsp8R1DTGkaMwXLzPTB8dJt3qQc4EjGYzEHxjIuw05mpULXTIK+yjrwqJ3mV5uNEUTVZnqvd0Gzg6k7X9A+UoeFQQTX2AAuWJieU5rPvdHmN22fdfXlVWPOVN9nyxz+Odd7xBFgU0SHmSfvAiEDGJdi9J+tVdW7+vK8Qt6GxWRX/OjuZ4XGepjg0OulVTa7oYZ40vbz5Ai63ue4/z05maHSw9wTAXZ+YNqppcWvN5yfKWHeizHsiO2dIBDNSwnA2qgFwus1lXW6NS9fX9sChfAeHChpOKscn2hmfaPfUHjVcOW6YNk9+cirqeHev5zgtiu9ekciwmGBvItn4Km59glk/fbK4xnucVoviWxNisQdYfZLN4moXJ4prKKtt+O4bJMFR4OjpZt9NWKCFiCAr4UE24kMDSIsJJiLIyumSWp+T/UXDI7l+RLT3BCbYZl4NblozlVVQzbMbzuLyHOcTM5P9PpFouu6yGQP8Wrfpeo9N92+9ltZ99Iokv9YdV2AnM9/hXW/JxPhL3ue/X5N6Scd5Xwf2+cCkBL/3mdVJ+7x/kn/rNl3v21MTL3mf/+8q/8pf0/Wea/KdaO1b21t/0cppaI4VVvPGzjzvuo/PTGJkbIjP70CAVXkT69b2+ew8/8pBS+s+My/lko7zYif69clpfZJ7uKCa5zee8677TzMHMDAikFq39ib6NS7DewGg1vN6f27Db2b9GYbFoqioc1Pk0NS462uczYsGrf2Jchnwj2OlWBSEBliwB1q9z0lhAdgDgrzzThTXkJHd8Ps1a3A40weGNYqh/hhpNm/n+Qp2nKtEY9YKZ+Y5ejwZuhipGWpCaoYuX7qmGr1nB/rzVXDaj7PYwEDP/WLsEGKHqgqO1AWRGZXGuNKTjBoxEMv8m83EJyoWZbN5rzb5VP17nk9lnST7XC7j0pIYPcm/1MQ4vB/92vOeQQnaN6TyV+cqeGXLBW9V//yhESRHBPleZfI0TWnadOVsaQ378xzEhQYQZLV4Ep46ciud5Fc6KWt0tQ3wnPQpn6uG4xLsjEsMMU9i65tWKU9tSZOrybsuVLL1TIX3R/natEiuHR7lbXYRYFUEWM0rwIGeP55Wi2rXH62mLrauoc3vrXFTHKfbvIK97ngpa483JAlXDwnnioHhrSQXDa8NA/bnVbEvt+EK8oK0SG4dHUNMsI3QQMtF+xh0d3PArvpsuyLW9q7rNjSlNS5Kqt2sOlLMplPlPt/ndcOjiQi2mglQoLXVZnY9eZwnK5H+HrJPKUP9ZJ/tTcBchjab3boNDuU7+PWXuWbNkFXxb/NSGJ9ob7PPWk/9xncVGU2uHSQZurxotxsO70N/tQmd8SXU1YI9lCO2WDOpKTtJ+pg06mYtosIWTKUliAoVRIW2UemCilo3FXVm05jsgjKyyg20p0VtVKDCYrP5tHV2unWbtSHtrVK+lKZux4qqeWb9OWo6qa2SVUF8aACJYfWPQBJDA0gKDyAxNIDwICtHCmv67clzZ8ba2/6AXEx/7o9Vr6PfSU8dp/wtEx0lZah36YtJ36Uk1F1FkqF2kP/8/Z/WGs6dQu/YiN5p3jOkNjSSc1Ov5UzaNPaUKr4s1mhPYyKbReG6yP+SQKsiPNCKW2ufmo+hUUGkxQab1ftNmv4ENH5tVWRkV7HtbIV33TvGxnD/pIQuOf4tp8v59Y4cQgMsVNYZuLV5kvf8Nak+7fVrXWaNR+PpWrdm+9lyb/W3Am4bHcP9k+Iv2gm93uVw8gz96w+I6Ftlr578LRMdJWVIdFRvKkPSZ0gIQBcXYuz4gsLduzhdpTkdnszpsfdzNmwA2U6r2cb2lNlRUTeqPh4ZF8LU5DDCg6yEB1kIC/Q0jwmyEhZo9Y7U1Kzd/HT/2s0DpEQEsetCpbfmaO2xMmakhDMyrvNOvAytWXmgkL8eKGJMfAg/njOQnApns5O8+uNpTUJoALuzq7zHeWVquF+JEJgn95d6MtmRdbtbR49z9uje8wdE9K2yJ4QQon2kZqiJ3pTFio7Zn5HF9uP52LWLmrJyTjsDOBM6gMqAhvtKJIYFMCQqiCHRQQyNCmZIdBAl1S6e+/zcJTdzutSr+vVXn2PsVv5nfxHF1S4em57IwrSodm2nJbUug199mcO2sxVcMyySZdMTCbBePOnxJ9a+dKW8L5HfIdFRUoZER0kZEh3Vm8qQNJNrh970xQn/ON0G2bklnM0u5ExhJWcrXByvsVFksXtHzwp0OxkSUMeQAdEMTY5mSFQQg6OCCA20trjNjpzsd0YZKq918/OtF9if6+CmkVEsnZqIzc/al6aKHE5e+uICJ4treGByPN8YHeP3zf5Ez5DfIdFRUoZER0kZEh3Vm8qQNJMTfdrhvVlkHs9mdFwwMWFBnMkv52xZHWdrLJzVdrIDInFZzKJs0SEMqC7ErmsosocACot2c2doEXfdPs/vffZ0s5iIICv/Pj+Vd/cW8NHhYk6X1vIvVw8kKrh9/2WPFVXz0hcXqHYaPDV3INNTwrsoYiGEEEKIvkeSIdFr5ecVsmbNV3xoGYKhBsB5PDU9oQAkUkaqqmKaNYdB4VYGx4czMDmOwIQryMo6w7/tr8OlrNi0m/FpST16LJfCalE8PCWBodFBvP5VLj/8x2menJPC8Nhgv9bfeqacX32ZQ1SwlX9fNIgh0f6tJ4QQQghxuZBkSPQalXVuDuQ52H88l30XyrigwsCWZt7RSynQBlfqAr45O53U5FjsrTRxAxg9KZ2fkEXmifbdt6c3mjc0ktTIIH76xXmeXHeGZdOTmD8sstXltdasPFDE/xwoZLRnoIT21igJIYQQQlwO5AxJ9Jg6t0FWQTX7ch3sy63iRFE1Bopgdy1jyi9wbbSVyMQEfpsd7K3huW1CAqOG+Dfk9OhJ6X06CWosLSaY5TcM4Wdbs/nllzmcKKnh4ckJzUZxq3UZ/HpHDlvPVHDNsAiWTU/q0EAJQgghhBD9mSRDoltkFVRzIK+KmBAbZTVu9uVWcaigmjq3xoJmhCOHO/IPMsGZz8jpkwm8/VpUqNm/ZcDe/lHD01GRwTaevyaVtzPy+SSrhDMltfzz7GQiPLU+RQ4nL39xgRPFNTwoAyUIIYQQQrRJkiHR5b4+X8FLmy+Y9/HxGBRmZRE5TDi6iTF5B7GnpKKuvRU1dRbK5lss+1MNT0fZLIpHpiUyLCaYN77K5YdrTvOt8XEcK6phy5kKnIbmybkDmSEDJQghhBBCtEmSIdFlalwGfz9czP9mFnkTIYXmG84TLPnHn8Bww6QZWJY8D8NHSy1GO1wzLJLUyEB+svE8v9qR653/TzOTJBESQgghhPCTJEOi07kNzecny/jL/kKKq12MDTc4WurGrSzYtJsrDm9AzbsBteAWVHzfG+WttxgRG8Ki4ZH87WAxABagyOHu2aCEEEIIIfoQSYZEp9Fak5FdxTt7CjhTVsuoCAs/cmWS/tlKjgQnkhmVxrjSk6TPuRLLrff1dLj9whUDw/k4qwSXobFZFOMS7T0dkhBCCCFEnyHJkOgUJ4treHtPPvtyHSTZXPyoeCszN61GWSyQNppRp44wqvI8WG2ocVN7Otx+Iz0+hBcWDCIzz8G4RHuP3ihWCCGEEKKvkWSoh2UVVPfpE9mCKif/va+ATafKCcXJ0tMbuO7MFwTExaO++QBq5jWoqBj0iSz0kQOoUeNRaTIYQmdKjw/pk2VHCCGEEKKnSTLUg7IKqnlq3RncGgIsihcXDuozJ7VVdW7e35fHJ8dK0W6DW89v4fYLWwmbOAV1+/MwcpxZK+Sh0tIlCRJCCCGEEL2KJEM9KDPPgdszyprT0PxiezaPXzmgV/f7OJBxmL8fKuSgjsBhCWJu7h6+VX2QxJkzUTN+iwqL6OkQhRBCCCGE8Eu3JUN79+5lxYoVGIbBggULuO2223zeLyws5PXXX6eqqgrDMLj33nuZMmVKd4XXI1IjAwFQgEWBo87N0+vPMj7RzrfGxzG2lyRF2u2GU0fYvmUvPwuYDCoehcH3Kndy7TdmwNB7ZVhsIYQQQgjR53RLMmQYBn/84x955plniI2N5cknn2TatGmkpKR4l3n//feZOXMmixYt4vz58/z0pz/t98lQrada6IaRUcwdEsnQ6CDWHi/l/YNFPLX+LBMS7dwzIY6xCd2fFOnyUnRmBmTuRh/cQ01NLb+f8S/e95XWlMUNQg0b1e2xCSGEEEII0Rm6JRk6fvw4SUlJJCYmAnDVVVexa9cun2RIKYXD4QDA4XAQHR3dHaH1qMw8B6EBFh6ZmojVYtas3JIew6LhUXxWnxStaz0p6sxBCbRhwJnj6ANfow/shjPHQWuIiIJJM3gjdh6lFYHYDDeGVti0m3Fpco8gIYQQQgjRd3VLMlRcXExsbKx3OjY2lmPHjvksc+edd/Liiy+yZs0aamtrefbZZ1vc1vr161m/fj0Ar7zyCnFxcZ0aq81m6/RttuZQ4RkmpUSSmBDf7L2lSQncO8PN3zNz+fPX53lq3VmmpUaydMYgJg6MpO7wfkpefQrcbrTVRthD/5fAkWNR9jCUPRSLPQwCA1tsvlaXdQDnwT3Yho5EV1VQm/EltRk70OWloBQBI8cSeM8jBE2diW3oSP68+wJbt59h2awhjHEVsPvwOaaOTmXylZO742Pqc7qzDIn+ScqQ6CgpQ6KjpAyJjuorZajXDKCwbds25s2bxy233MLRo0d57bXXWL58OZZGI5IBLFy4kIULF3qnCwsLOzWOuLi4Tt9mS4qrXZwrrWbhsLCL7m9BahCzBwxlzbFSPjhUxLK/HWBCkp27z2zAYk/23Mj0BKP+8J/NV7ZaIdgOIXbz2W4HtwGnjoBhNCwXFo4aOwU1fhpqzGSM8AhqgBrg6wNneWv7eeYMjmDR4CCUSiV1eCrQ+Z99f9FdZUj0X1KGREdJGRIdJWVIdFRvKkPJycmtvtctyVBMTAxFRUXe6aKiImJiYnyW+fzzz3nqqacAGDlyJE6nk4qKCiIjI7sjxG6XmWc2CRyXENrmskE2C7eOjuH6EVHepOjpoJmoyTMACDBcPJ9YwOikCHR1FdQ4oLoavK8d6GoH1FRDYXajREih5l6Huve7KIu12X7Pl9eyfFs2Q6OD+L9XJskgCUIIIYQQol/plmQoLS2NnJwc8vPziYmJYfv27Tz++OM+y8TFxZGZmcm8efM4f/48TqeTiIj+O0xzZp4De4CFodFBfq9TnxRdF2/wH3/ZQkZMOiiF0xrIoYGTGDMulrbSFX0iC2P5M+B2gdVm3hS1hUSoqs7Ny19cIMCieGpuCkE2SwtbE0IIIYQQou/qlmTIarWydOlSXnrpJQzDYP78+aSmprJy5UrS0tKYNm0aDzzwAG+99RaffvopAMuWLevXNRGZ+Q7GxId4B05oj8AdG7jzzBYOxI/GaYAGlNJ+ravS0rH88MWLDrzgNjS/2JZNbkUdLywYRHxoQLtjFEIIIYQQorfrtj5DU6ZMaTZU9t133+19nZKSwgsvvNBd4fSokmoXF8rruDat/U0AtWGgt65j1MABvLhwMLsuVPDl2Ur+vK+QkAArN45sexQ+lZZ+0dHn/rK/kK+zq3j0isRec68jIYQQQgghOpu0feoB3v5Cl5JoZO2DonzU1YtIjw/h/kkJ/OLGIUxNDuWtXXm8sycfQ/tXS9SSLafL+dvBIq4bHsX1I6IueTtCCCGEEEL0dpIM9YDMfAchNgvDooPbva7evNYc/W3Sld55wTYLT85J4YYRUXxwqJjl27KpcxsX2UrLThbX8OsdOYyOD+H/TEvs180UhRBCCCGE6DVDa19OMvMcjElof38hXVGG3vsVav5NqADffjxWi+K7VySSEBrAO3sLKKl28eScFMKDmg+O0JKyGhc/3Xye8CArP756IAFWSYSEEEIIIUT/JjVD3ay02sX58rpLaiKnv/wc3C7U1de2+L5Sim+OjeWHs5I5UljDj9eeIa+yrs3tugzNz7ZmU1rj5sk5A4kKkRxZCCGEEEL0f5IMdbPMfLO/0Ph2JkNaa/SWtZCWjkoedNFl5wyJ4CfXpFJS4+JfPjvDsaLqiy7/p915ZOY5+N6MJEbEhrQrLiGEEEIIIfoqSYa6WWbeJfYXOnYIci+grr7Or8XHJtr5j0WDCbQqnl53ll3nK1tcbt3xUj49Wspto2OYN7R/3uBWCCGEEEKIlkgy1M0OXGp/oa1rIcSOmjbL73VSI4P42XVDSIkM5OXN51lzrMTn/ayCat7clcukJDsPTIpvVzxCCCGEEEL0dZIMdaPSGk9/oYR2NpFzVKJ3b0NNn4MKal+NUnSIjZcWDmbygFB+uzOPdz1Dbxc5nLyy+Txx9gB+NHvgJd38VQghhBBCiL7Mr57yb7/9NvPmzWPIkCFdHE7/dvAS7y+kv/oC6ur8biLXVEiAhafnpvDWrjzeP1TMieIazpXXUeU0+MmCQX6POCeEEEIIIUR/4lcyZBgGL730EhEREVx99dVcffXVxMbGdnVs/c6BPAfBNgtpMf7X7mitzXsLDRqGGpx2yfu2WhSPTU9EKVhzrBQAm0XhcLb/fkRCCCGEEEL0B34lQ0uXLuWhhx5iz549bNmyhQ8++IARI0YwZ84cZsyYQXBw+28eejnKzHcwJr6d/YXOHIfzp1D3Pdrh/SuliLcHoAANGFqTmecgPV5GkBNCCCGEEJcfv28oY7FYmDp1KlOnTuXcuXP8+te/5o033uAPf/gDs2bN4q677iImJqYrY+3TSmtcnCurY347R2zTW9ZCYCBq+txOiWNcop0Aq8JlaGwWdUn3OxJCCCGEEKI/8DsZcjgc7Nixgy1btnDmzBlmzJjBt7/9beLi4li1ahUvv/wyr776alfG2qcdzG9/fyFdU43+ajNq6myUPbRT4kiPD+GFBYPIzHMwLtEutUJCCCGEEOKy5VcytHz5cvbt28fo0aO59tprueKKKwgICPC+/8ADD/DQQw91VYz9Qmaeg2Cbal9/oa+3Qm01as6iTo0lPT5EkiAhhBBCCHHZ8ysZGjFiBN/+9reJiopq8X2LxcLvf//7Tg2sv8nMczA63o6tHf2F9Ja1MCAV0kZ3YWRCCCGEEEJcnvy6z9CECRNwuVw+8woLCzl9+rR3OigoqFMD60/KalycLatrXxO5C2fg5BHU7GtRSu4BJIQQQgghRGfzKxl67bXXcLvdPvNcLhe/+c1vuiSo/qa+v9D49iRDW9aCzYaaeU1XhSWEEEIIIcRlza9kqLCwkMTERJ95SUlJFBQUdElQ/U17+wtpZx16xybU5Jmo8Igujk4IIYQQQojLk1/JUExMDCdPnvSZd/LkSaKjo7skqP4mM6+a9Hb0F9IZX0JVBWr2tV0cmRBCCCGEEJcvvwZQuOmmm/j5z3/O4sWLSUxMJC8vj08++YRvfvObXR1fn1de4+JMWS1zhvhfw6O3rIW4REif0IWRCSGEEEIIcXnzKxlauHAhoaGhfP755xQVFREbG8sDDzzAlVde2dXx9XkH86sB/+8vpPOz4cgB1G1LUBa/Ku6EEEIIIYQQl8Dvm67OnDmTmTNndmUs/dKBfAdBVsXwWD/7C21ZBxYLataCLo5MCCGEEEKIy5vfyVBpaSnHjx+noqICrbV3/jXXyGhnF2PeXyjEr/5C2uVCb98A46ehomK7ITohhBBCCCEuX34lQzt37uS1115jwIABnDt3jtTUVM6dO0d6erokQxdRXuvmTGktV0+M82+F/bugvBTL1dd1bWBCCCGEEEII/5KhlStXsmzZMmbOnMnDDz/Mz372MzZu3Mi5c+e6Or4+rf7+Qv72FzK2rIWoGBg3pSvDEkIIIYQQQtCO+ww17S80d+5cNm/e3CVB9ReZeQ4CrYrhMSFtLquLC+BgBmrWQpTV2g3RCSGEEEIIcXnzKxmKiIigtLQUgPj4eI4ePUpeXh6GYXRpcH1dfX+hAKsf/YW2rgeQewsJIYQQQgjRTfxqJrdgwQKysrK48soruemmm3j++edRSnHzzTd3dXx9VoWnv9C9fvQX0oYbvW0djJ6IikvshuiEEEIIIYQQfiVDixcvxuK5583cuXMZO3YsNTU1pKSkdGlwfdnBfAcaGJ/gR3+hQ3uhuBDLnUu7PC4hhBBCCCGEqc1mcoZhcP/99+N0Or3z4uLiJBFqg7e/UGzb/YWMLWshLAImzeiGyIQQQgghhBDgRzJksVhITk6moqKiO+LpNzLzHaT70V/I2L8L9uyAMZNQtoBuik4IIYQQQgjhVzO52bNn8x//8R/ccMMNxMbGolTDCf64ceO6LLi+qqLWzemSWu6dcPH+QvpEFvqNl0FryPgSfSILlZbeTVEKIYQQQghxefMrGVq7di0A7733ns98pRS/+c1vOj+qPu6Qp79QW/cX0kcOgNttThhu9JEDkgwJIYQQQgjRTfxKhl5//fWujqNfOZBv9hcaERt88QVDPMmSUmC1oUaN7/rghBBCCCGEEICfyZBon4N5DtLjQgiwttEl60QWBAajrvsmauwkqRUSQgghhBCiG/mVDD322GOtvvfb3/6204LpDypr3ZwqqeVbbfUXqqpA796Omn0tlsX3dFN0QgghhBBCiHp+JUPf//73faZLSkpYvXo1s2bN6pKg+rKDBX72F9qxCVxO1NWLuiUuIYQQQgghhC+/kqExY8Y0mzd27Fheeuklbrzxxk4Pqi+rv7/QyIv0F9Jao7eshcHDUYOGdWN0QgghhBBCiHpt3meoNTabjfz8/M6MpV84mO9gVFv9hU4dhQtnpFZICCGEEEKIHuRXzdDKlSt9pmtra9mzZw+TJ0/ukqD6qso6NyeLa7mnrf5CW9dBYBBq+pxuikwIIYQQQgjRlF/JUFFRkc90UFAQN998M3PmyMl8Y/X3Fxqf0Hp/IV3jQO/cjLpiNirk4v2KhBBCCCGEEF3Hr2Ro2bJlXR1Hv5CZ5yDAohgRd5H+Qju3QG0N6urrujEyIYQQQgghRFN+9Rn66KOPOH78uM+848eP8/e//71LguqrMvOrGRUfQuBF+gvpresgeRAMG9WNkQkhhBBCCCGa8isZWr16NSkpKT7zUlJSWL16dZcE1RdV1rk5VVJz8SZy50/BqaOoq69FKdWN0QkhhBBCCCGa8isZcrlc2Gy+LepsNht1dXVdElRfdDi/GkNf/P5Cess6sNlQV87vxsiEEEIIIYQQLfGrz9CwYcP47LPPuOmmm7zz1q5dy7Bh/t8jZ+/evaxYsQLDMFiwYAG33XZbs2W2b9/Oe++9h1KKwYMH88QTT/i9/Z6WmW/2FxrZSn8hXVeL3rERNeUqVFhEN0cnhBBCCCGEaMqvZOjBBx/kxRdfZPPmzSQmJpKXl0dpaSnPPvusXzsxDIM//vGPPPPMM8TGxvLkk08ybdo0n6Z3OTk5fPTRR7zwwguEhYVRVlZ2aUfUQ3adryQmxMrJ4lrS40Oava8ztoOjCjX72h6ITgghhBBCCNGUX8lQamoqv/rVr9i9ezdFRUXMmDGDqVOnEhzc+qhpjR0/fpykpCQSExMBuOqqq9i1a5dPMrRhwwauu+46wsLCAIiMjGzvsfSYPTmVXKgwmww+u+EsLywY1Cwh0lvWQXwSjBrfEyEKIYQQQgghmvArGSouLiYwMJBZs2Z551VWVlJcXExMTIxf68fGxnqnY2NjOXbsmM8y2dnZADz77LMYhsGdd97JpEmT/DqInvb1hSrva5ehycxz+CRDOvcCHM1EfeN+lMWvblpCCCGEEEKILuZXMvTzn/+cxx57zFtrA2aC8+abb/Lyyy93SiCGYZCTk8Nzzz1HcXExzz33HK+++iqhoaE+y61fv57169cD8MorrxAXot0y/AAAIABJREFUF9cp+69ns9navc1bJgay7kQZTrdBgNXC7FEDiItr6BdUsXolDouV2JvvxBrTufGK3udSypAQjUkZEh0lZUh0lJQh0VF9pQz5lQxlZ2czaNAgn3mDBg3iwoULfu0kJiaGoqIi73RRUVGzGqWYmBhGjBiBzWYjISGBAQMGkJOTw/Dhw32WW7hwIQsXLvROFxYW+hWDv+Li4tq9zaQA+Mk1qWTmORiXaCcpoM67De1yYqxfBROuoMQAOjle0ftcShkSojEpQ6KjpAyJjpIyJDqqN5Wh5OTkVt/zq81WREQEubm5PvNyc3MJDw/3K4C0tDRycnLIz8/H5XKxfft2pk2b5rPM9OnTOXjwIADl5eXk5OR4+xj1BenxIdwxLrb54An7dkFFGZarZeAEIYQQQgghehO/aobmz5/P8uXLueeee0hMTCQ3N5eVK1dyzTXX+LUTq9XK0qVLeemllzAMg/nz55OamsrKlStJS0tj2rRpTJw4kX379vGDH/wAi8XCkiVL/E62ejNj61qIioVxU3o6FCGEEEIIIUQjSmut21rIMAxWrVrF559/TlFREbGxsVxzzTXcfPPNWHp4QID6gRc6S2dW6emifIwn/w/qpruw3Hpfp2xT9H69qVpY9E1ShkRHSRkSHSVlSHRUbypDF2sm51fNkMViYfHixSxevLjTgroc6G3mQA9ybyEhhBBCCCF6H7+SIQCXy0V2djbl5eU+88eNG9fpQfUH2nCbydCYSajYhJ4ORwghhBBCCNGEX8lQVlYWv/jFL3A6nVRXVxMSEkJNTQ2xsbH85je/6eoY+6aDe6C4EMtd3+7pSIQQQgghhBAt8KvDzzvvvMPixYtZsWIFISEhrFixgttvv51FixZ1dXx9lrFlLYRHwsTpPR2KEEIIIYQQogV+JUPZ2dnceOONPvNuu+02Pv300y4Jqq/TZSWwfxfqqmtQtoCeDkcIIYQQQgjRAr+SIbvdTnV1NQBRUVGcP3+eyspKampqujS4vkpv/xzcbhk4QQghhBBCiF7Mrz5DM2bMYM+ePcyePZv58+fz/PPPY7VaufLKK7s6vj5Ha43euhZGjkUlpfR0OEIIIYQQQohW+JUMPfTQQ97XixcvZuTIkVRXVzNx4sSuiqvvOnIA8nNQN9/T05EIIYQQQgghLsLvobUbS09P7+w4+g29ZR3YQ1FTr+rpUIQQQgghhBAX4VefIeEfXVWBztiOmjEPFRjU0+EIIYQQQgghLkKSoU6kd2wClxN1tQw5LoQQQgghRG8nyVAn0Vqjt6yFISNQqUN7OhwhhBBCCCFEG9qdDBmG4fMQHiePwIUzqKtlOG0hhBDi/7d379FR13f+x18zE8gVQiYJ4S4SwCyBlKXJmvJDSswABnCJXS5LxdZCLcWIXFwkZfureLgUVwKiZoXFCEVdG1G8YdXDRdSCsnFZQOBHIBAwSCTkAuSeTGZ+f1BmTSFh4uQ7STrPxzke53t/T/I+Z/Li8/1+BgA6ArcmUDhz5oyysrL09ddfq66urtG27OxsQwrraBx/2iZZ/KTIHm1dCgAAAAA3uBWGMjMz9cMf/lBz586Vvz8TA/w1x/87JB3JkSQ5n1sh52MrZIpmxj0AAACgPXMrDBUXF2vGjBkymUxG19MxHc7539cNdjlzvyIMAQAAAO2cW88MJSQk6PDhw0bX0mGZEu6SOnWWzGbJ4ifTHcPauiQAAAAAt+DWyFB9fb3WrFmjmJgYdevWrdG2Rx55xJDCOhJTdIzMj624NiJ0xzBGhQAAAIAOwK0w1KdPH/Xp08foWjo0U3QMIQgAAADoQNwKQ1OnTjW6DgAAAADwKrfCkCQdO3ZMn3zyicrKyhQWFqbRo0dr6NChRtYGAAAAAIZxawKF3bt3a926derWrZv+4R/+QWFhYVq/fr127dpldH0AAAAAYAi3Robeffdd/fa3v1X//v1d60aOHKmMjAzZbDajagMAAAAAw7g1MlReXn7DBAq9evVSRUWFIUUBAAAAgNHcCkMxMTHaunWramtrJUk1NTV6+eWXNXjwYEOLAwAAAACjuHWb3EMPPaRnnnlGDz74oEJCQlRRUaHBgwdr/vz5RtcHAAAAAIZwKwyFhYXpySefVHFxsS5fvqywsDCFh4cbXRsAAAAAGKbJMOR0OmUymSRJDodDkmS1WmW1WhutM5vdutMOAAAAANqVJsPQgw8+qD/84Q+SpBkzZjR5guzs7NavCgAAAAAM1mQYysjIcL1+/vnnvVIMAAAAAHhLk/e4RUREuF5//vnnioyMvOG/AwcOeKVIAAAAAGhtbj3w8+abb7ZoPQAAAAC0d83OJnf06FFJ1yZLuP76uosXLyowMNC4ygAAAADAQM2GoRdeeEGSVFdX53otSSaTSd26ddOsWbOMrQ4AAAAADNJsGMrMzJR0bQKFRx55xCsFAQAAAIA3uPXMEEEIAAAAwN+aZkeGrquqqtK2bdt0/PhxlZeXy+l0urZ99/Y5AAAAAOgo3BoZevHFF5Wfn68pU6aooqJCs2bNUkREhCZOnGh0fQAAAABgCLfC0JEjR/TYY48pISFBZrNZCQkJWrhwoT777DOj6wMAAAAAQ7gVhpxOp4KCgiRJAQEBqqqqUrdu3fTtt98aWhwAAAAAGMWtZ4Zuu+02HT9+XMOGDVNMTIxefPFFBQQEqGfPnkbXBwAAAACGcGtkaM6cOYqMjJQk/eIXv1Dnzp1VWVnJLHMAAAAAOiy3RoaioqJcr0NDQ/XrX//asIIAAAAAwBvcGhl66aWXlJub22hdbm6utmzZYkRNAAAAAGA4t8LQvn37FB0d3WjdgAED9Oc//9mQogAAAADAaG6FIZPJJIfD0Widw+Fo9OWrt3Lo0CHNnz9f8+bN09tvv93kfl988YWmTZum06dPu31uAAAAAGgpt8JQTEyM/vjHP7oCkcPh0LZt2xQTE+PWRRwOh7KysrR06VKtW7dO+/bt0/nz52/Yr7q6Wh988IEGDRrUgrcAAAAAAC3n1gQKv/jFL7R69WrNmTNHERERKi4uVlhYmJYsWeLWRfLy8tSjRw/XRAwjR45UTk6O+vTp02i/7OxsTZ48We+++24L3wYAAAAAtIxbYSg8PFxPPfWU8vLyVFJSovDwcA0cOFBms1sDSyotLVV4eHij8506darRPmfOnFFxcbFGjBhBGAIAAABgOLfCkCSZzWYNHjzYkCIcDoe2bt2qhx9++Jb77tq1S7t27ZIkrV69WhEREa1ai5+fX6ufE76FHoKn6CF4ih6Cp+gheKqj9FCTYWjhwoVat26dJGnu3LlNnuCFF1645UWsVqtKSkpcyyUlJbJara7lmpoaFRQU6Mknn5QkXb58Wf/2b/+mxx9//IZZ7Gw2m2w2m2u5uLj4ltdvieu3AQLfFz0ET9FD8BQ9BE/RQ/BUe+qhXr16NbmtyTA0Z84c1+t58+Z5VEB0dLQKCwtVVFQkq9Wq/fv369FHH3VtDwoKUlZWlmt52bJleuCBB24IQgAAAADQWpoMQy+//LJWrlwpSTp27JimTp36vS9isVg0a9YsrVy5Ug6HQ0lJSerbt6+ys7MVHR2t+Pj4731uAAAAAPg+mgxDFy5cUF1dnTp37qwdO3Z4FIYkacSIERoxYkSjddOnT7/pvsuWLfPoWgAAAABwK02GoYSEBM2fP1/du3dXXV2dnnjiiZvud/05HwAAAADoSJoMQw8//LBOnDihoqIi5eXlKSkpyZt1AQAAAIChmp1aOyYmRjExMbLb7RozZoyXSgIAAAAA4zUZho4fP64hQ4ZIkrp3766jR4/edL+hQ4caUxkAAAAAGKjJMJSVlaWMjAxJTX+XkMlk0vPPP29MZQAAAABgoCbD0PUgJEmZmZleKQYAAAAAvMX8fQ46evSojh8/3tq1AAAAAIDXuBWGnnjiCZ04cUKS9Pbbb2v9+vVav369tm/fbmhxAAAAAGAUt8JQQUGBBg8eLEnavXu3nnjiCa1cuVI7d+40tDgAAAAAMEqzU2tf53Q6JUnffvutJKlPnz6SpMrKSoPKAgAAAABjuRWG7rjjDr300ksqKytTQkKCpGvBqEuXLoYWBwAAAABGces2ubS0NAUFBem2227TtGnTJEkXLlzQhAkTDC0OAAAAAIzi1shQly5d9NOf/rTRuhEjRhhSEAAAAAB4g1sjQzt27NDZs2clSSdPntTcuXOVlpamkydPGlkbAAAAABjGrTD0/vvvq3v37pKk1157TZMmTdI//dM/acuWLUbWBgAAAACGcSsMVVVVKSgoSNXV1Tp79qxSUlJ0991368KFC0bXBwAAAACGcOuZofDwcOXm5qqgoEB/93d/J7PZrKqqKpnNbmUpAAAAAGh33ApDM2fO1Nq1a+Xn56fHHntMknTw4EENHDjQ0OIAAAAAwChuhaERI0Zo48aNjdYlJiYqMTHRkKIAAAAAwGhuhaHrqqurVV5eLqfT6VoXFRXV6kUBAAAAgNHcCkPnz5/Xs88+q3Pnzt2wLTs7u9WLAgAAAACjuTUDwosvvqjY2Fi99NJLCgoK0ubNmzV27FilpaUZXR8AAAAAGMKtMHTu3Dndf//9Cg4OltPpVFBQkGbOnMmoEAAAAIAOy60w1KlTJzU0NEiSunTpouLiYjmdTlVUVBhaHAAAAAAYxa1nhmJiYvT5559rzJgxSkxM1KpVq9SpUyfFxsYaXR8AAAAAGMKtMLRo0SLX6xkzZqhv376qqanR6NGjDSsMAAAAAIzUoqm1JclsNhOCAAAAAHR4TYah5557TiaT6ZYneOSRR1q1IAAAAADwhibDUI8ePbxZBwAAAAB4VZNhaOrUqd6sAwAAAAC8qtmptXNzc/XKK6/cdNurr76qkydPGlIUAAAAABit2TC0fft2DRky5KbbhgwZou3btxtSFAAAAAAYrdkwdPbsWQ0fPvym2+Li4pSfn29IUQAAAABgtGbDUHV1tex2+023NTQ0qLq62pCiAAAAAMBozYah3r176/DhwzfddvjwYfXu3duQogAAAADAaM2GoYkTJ+o//uM/dODAATkcDkmSw+HQgQMHtGnTJk2cONErRQIAAABAa2tyam1JGjVqlC5fvqzMzEzV19era9euunr1qjp16qRp06Zp1KhR3qoTAAAAAFpVs2FIkiZNmqS7775bJ0+eVEVFhUJCQjR48GAFBQV5oz4AAAAAMMQtw5AkBQUFNTmrHAAAAAB0RM0+MwQAAAAAf6sIQwAAAAB8EmEIAAAAgE8iDAEAAADwSYQhAAAAAD6JMAQAAADAJxGGAAAAAPgkt75nqDUcOnRImzdvlsPhUHJyslJTUxtt37Fjh3bv3i2LxaKuXbtq7ty5ioyM9FZ5AAAAAHyMV0aGHA6HsrKytHTpUq1bt0779u3T+fPnG+3Tv39/rV69WmvWrFFiYqJeeeUVb5QGAAAAwEd5JQzl5eWpR48eioqKkp+fn0aOHKmcnJxG+wwdOlT+/v6SpEGDBqm0tNQbpQEAAADwUV65Ta60tFTh4eGu5fDwcJ06darJ/ffs2aPhw4ffdNuuXbu0a9cuSdLq1asVERHRqrX6+fm1+jnhW+gheIoegqfoIXiKHoKnOkoPee2ZIXd9+umnOnPmjJYtW3bT7TabTTabzbVcXFzcqtePiIho9XPCt9BD8BQ9BE/RQ/AUPQRPtace6tWrV5PbvHKbnNVqVUlJiWu5pKREVqv1hv2OHDmit956S48//rg6derkjdIAAAAA+CivhKHo6GgVFhaqqKhIdrtd+/fvV3x8fKN98vPztWnTJj3++OMKDQ31RlkAAAAAfJhXbpOzWCyaNWuWVq5cKYfDoaSkJPXt21fZ2dmKjo5WfHy8XnnlFdXU1Gjt2rWSrg2tLVmyxBvlAQAAAPBBJqfT6WzrIjxx4cKFVj1fe7q/ER0TPQRP0UPwFD0ET9FD8FR76qE2f2YIAAAAANobwhAAAAAAn0QYAgAAAOCTCEMAAAAAfBJhCAAAAIBPIgwBAAAA8EmEIQAAAAA+iTAEAAAAwCcRhgAAAAD4JMIQAAAAAJ9EGAIAAADgk/zaugAAAACgvXM6naqpqZHD4ZDJZGrrctq9ixcvqra21mvXczqdMpvNCggIaNHvhzAEAAAA3EJNTY06deokPz/+fHaHn5+fLBaLV69pt9tVU1OjwMBAt4/hNjkAAADgFhwOB0GonfPz85PD4WjRMYQhAAAA4Ba4Na5jaOnviXgLAAAAtHOlpaWaPn26JOnSpUuyWCyyWq2SpPfff1+dO3du8tjDhw/rjTfe0PLly5u9xj/+4z/q3Xffbb2iOwDCEAAAANDOWa1W7dy5U5KUkZGh4OBg/frXv3Ztt9vtTd7G94Mf/EA/+MEPbnkNXwtCEmEIAAAAMITz9Ak5c7+S6Y5hMkXHtPr5FyxYIH9/fx07dkzx8fGaPHmyfve736m2tlYBAQFau3atBg4cqP3792vDhg3aunWrMjIy9M033+jrr7/WN998o1/+8peaPXu2JGnQoEE6deqU9u/fr7Vr1yosLEy5ubmKi4vTc889J5PJpN27d+vJJ59UUFCQEhISdO7cOW3durVRXQUFBZo/f74qKyslSStWrFBCQoIkKTMzU9u3b5fJZNLdd9+tpUuXKj8/X+np6SopKZHFYtHGjRvVv3//Vv953QxhCAAAAGgBxx83yVmQ3/xO1VXS+XzJ6ZTTZJL63C4FBjW5u6nv7TL/80MtrqWwsFDvvPOOLBaLysvL9dZbb8nPz0+ffvqpnnrqKW3atOmGY/Ly8rRt2zZVVlbqrrvu0s9+9jN16tSp0T5Hjx7Vnj171KNHD02ePFk5OTmKi4vTkiVLtH37dvXr108PP/zwTWuKiIjQ66+/Lj8/P505c0ZpaWn64IMPtGfPHn300UfasWOHAgMDVVZWJkmaN2+e0tLSlJKSopqaGjmdzhb/HL4vwhAAAADQ2qorpet/1Dud15abCUPf16RJk1xTWF+9elULFixQfn6+TCaT6uvrb3pMcnKy/P395e/vr4iICF26dEm9evVqtM/w4cNd62JjY1VQUKCgoCDddttt6tevnyQpNTVVr7zyyg3nr6+vV3p6uo4ePSqz2awzZ85Ikj777DNNnz7dNfV1WFiYKioqVFhYqJSUFElSQEBAK/xU3EcYAgAAAFrAnREc5+kTcmT8VmqwSxY/mX/5mCG3ygUF/W/AevrppzVy5EhlZWWpoKBAU6ZMuekx/v7+rtcWi0UNDQ037PPdCRksFovsdrvbNW3atEmRkZHauXOnHA6HBgwY4Pax3sbU2gAAAEArM0XHyPzYCpkm33/t/wYEob9WXl6uHj16SJJef/31Vj9/dHS0zp07p4KCAklNT7hw9epVRUVFyWw2680333SFrdGjRys7O1vV1dWSpLKyMoWEhKhnz5768MMPJUm1tbWu7d5AGAIAAAAMYIqOkXnCVK8EIUmaO3eufv/732vcuHEtGslxV2BgoFatWqX7779f99xzj4KDg9W1a9cb9vv5z3+u7Oxs2Ww25eXluUavkpKSNG7cOKWkpGjs2LHasGGDJOnZZ59VVlaWbDabJk+erKKiolavvSkmpzefUDLAhQsXWvV8ERERKi4ubtVzwrfQQ/AUPQRP0UPwFD10o6qqqka3pPmqyspKBQcHy+l0aunSpbr99tv1q1/96ob9/Pz8DAlkt3Kz39NfPw/1XTwzBAAAAMAtr776qrZt26b6+noNHTpUDzzwQFuX5BHCEAAAAAC3/OpXv7rpSFBHxTNDAAAAAHwSYQgAAACATyIMAQAAAPBJhCEAAAAAPokwBAAAALRzU6ZM0d69exut27Rpk9LT05s95vDhw5KkBx54QFeuXLlhn4yMDNf3/TTlww8/1MmTJ13LTz/9tD799NMWVN9+EYYAAACAdi41NVXvvPNOo3XvvPOOUlNT3Tr+5ZdfVmho6Pe69l+HocWLF2v06NHf61ztDWEIAAAAMMCJS9V642iJTlyq9vhcEydO1O7du1VXVydJKigo0MWLF3XnnXcqPT1dKSkpSkpK0po1a256/J133qnS0lJJ0vr16zVq1Cilpqbq9OnTrn1effVVTZgwQTabTQ899JCqq6uVk5OjnTt3asWKFRo7dqzOnj2rBQsWaMeOHZKkzz77TOPGjVNycrIWLVqk2tpaSVJ8fLzWrFmj8ePHKzk5WXl5eTfUVFBQoPvuu0/jx4/X+PHjlZOT49qWmZmp5ORk2Ww2rVq1SpKUn5+v6dOny2azafz48Tp79qzHP1e+ZwgAAABogRe/vKj8sppm96mqb1B+WZ2ckkySbg/rrKBOlib3vz0sQL+Mj2pye1hYmIYPH66PP/5Y48eP1zvvvKN7771XJpNJS5YsUVhYmBoaGjR9+nQdP35cQ4YMuel5jhw5onfffVc7d+6U3W7XPffco7i4OElSSkqK7r//fknSU089pddee02zZs3S2LFjZbPZNGnSpEbnqqmp0cKFC5Wdna3o6Gg9+uij2rp1qx566CFJktVq1UcffaQtW7Zow4YNNwS1iIgIvfbaawoICNCZM2eUlpamDz74QHv27NFHH32kHTt2KDAwUGVlZZKkefPmKS0tTSkpKaqpqZHT6Wz2d+AORoYAAACAVlZZ59D1P9Wdf1n21HdvlfvuLXLvvfeea3QlNzdXp06davIcBw4c0D333KPAwEB16dJFY8eOdW3Lzc3Vfffdp+TkZL311lvKzc1ttp7Tp0+rX79+io6OliRNnTpVBw4ccG1PSUmRJMXFxamgoOCG4+vr67V48WIlJydrzpw5rlvxPvvsM02fPl2BgYGSrgXBiooKFRYWus4ZEBDg2u4JRoYAAACAFmhuBOe6E5eq9X93fy27wyk/s0mL/k9vxUR69sf7+PHjtWzZMn311Veqrq5WXFycvv76a23cuFHvv/++unXrpgULFqimpvlRq6YsXLhQWVlZio2NVXZ2tj7//HOP6vX395ckWSwWNTQ03LB906ZNioyM1M6dO+VwODRgwACPrvd9MDIEAAAAtLKYyEAtT+6n++MitTy5n8dBSJKCg4M1cuRILVq0yDUqVF5ersDAQHXt2lWXLl3Sxx9/3Ow5EhMT9dFHH6m6uloVFRXauXOna1tFRYWioqJUX1+vt956y7U+JCRElZWVN5wrOjpaBQUFys/PlyS9+eabSkxMdPv9XL16Vd27d5fZbNabb77pCkyjR49Wdna2qquvPWtVVlamkJAQ9ezZUx9++KEkqba21rXdE4QhAAAAwAAxkYGaMjS8VYLQdampqTp+/LgrDMXGxmro0KEaPXq00tLSlJCQ0Ozxw4YN07333quxY8dq5syZGj58uGvb4sWLNWnSJKWmpmrgwIGu9ZMnT9YLL7ygcePGNZq0ICAgQGvXrtWcOXOUnJwss9msBx54wO338vOf/1xvvPGGbDab8vLyFBQUJElKSkrSuHHjlJKSorFjx7qm/n722WeVlZUlm82myZMnq6ioyO1rNcXkbI0nj9rQhQsXWvV8ERERKi4ubtVzwrfQQ/AUPQRP0UPwFD10o6qqKtcf67g1Pz8/2e12r1/3Zr+nXr16Nbk/I0MAAAAAfBJhCAAAAIBPIgwBAAAA8EmEIQAAAOAWOvhj9j6jpb8nwhAAAABwC2azuU0mBID77Ha7zOaWxRu+dBUAAAC4hYCAANXU1Ki2tlYmk6mty2n3/P39VVtb67XrOZ1Omc1mBQQEtOg4r4WhQ4cOafPmzXI4HEpOTnbNjX5dfX29nn/+eZ05c0ZdunTRggUL1L17d2+VBwAAADTJZDIpMLD1vi/ob11HmZ7dK7fJORwOZWVlaenSpVq3bp327dun8+fPN9pnz549Cg4O1nPPPaeJEyfq1Vdf9UZpAAAAAHyUV8JQXl6eevTooaioKPn5+WnkyJHKyclptM+XX36pMWPGSJISExN19OhRHlQDAAAAYBivhKHS0lKFh4e7lsPDw1VaWtrkPhaLRUFBQSovL/dGeQAAAAB8UIebQGHXrl3atWuXJGn16tXq1atXq1/DiHPCt9BD8BQ9BE/RQ/AUPQRPdYQe8srIkNVqVUlJiWu5pKREVqu1yX0aGhpUVVWlLl263HAum82m1atXa/Xq1YbUmp6ebsh54TvoIXiKHoKn6CF4ih6CpzpKD3klDEVHR6uwsFBFRUWy2+3av3+/4uPjG+3zwx/+UHv37pUkffHFF4qNjWXaQgAAAACG8cptchaLRbNmzdLKlSvlcDiUlJSkvn37Kjs7W9HR0YqPj9fdd9+t559/XvPmzVNISIgWLFjgjdIAAAAA+CivPTM0YsQIjRgxotG66dOnu1537txZixYt8lY5TbLZbG1dAjo4egieoofgKXoInqKH4KmO0kMmJ/NXAwAAAPBBXnlmCAAAAADamw43tbaRDh06pM2bN8vhcCg5OVmpqaltXRLauX//93/XwYMHFRoaqoyMDElSRUWF1q1bp0uXLikyMlILFy5USEhIG1eK9qi4uFiZmZm6fPmyTCaTbDabJkyYQA/BbXV1dXriiSdkt9vV0NCgxMRETZs2TUVFRXrmmWdUXl6uAQMGaN68efLz4yMfTXM4HEpPT5fValV6ejo9hBZJS0tTQECAzGazLBaLVq9e3WE+yyzLli1b1tZFtAcOh0OrVq3Sv/7rv+q+++7T5s2bNWTIEHXt2rWtS0M7FhwcrKSkJOXk5Gj8+PGSpNdff119+/bVwoULVVZWpiNHjiguLq6NK0V7VFtbq8GDB2vGjBkaPXq0Nm7cqGHDhunDDz+kh+AWs9msUaNGacKECUpOTtZrr72mvn376o033lBSUpLmzJmjr776SmVlZYqOjm7rctGOvf/++7Lb7bLb7Ro1apQ2btxID8Ftf/rTn7R8+XLde++9rmeFOsrfQ9wm9xd5eXnq0aOHoqKi5Ofnp5H4s9R+AAAGcklEQVQjRyonJ6ety0I7N2TIkBv+lSMnJ0c//vGPJUk//vGP6SM0KSwsTAMGDJAkBQYGqnfv3iotLaWH4DaTyaSAgABJ176jr6GhQSaTSceOHVNiYqIkacyYMfQQmlVSUqKDBw8qOTlZkuR0OukheKyjfJYx3vkXpaWlCg8Pdy2Hh4fr1KlTbVgROqorV64oLCxMktStWzdduXKljStCR1BUVKT8/HwNHDiQHkKLOBwOLVmyRN9++63Gjx+vqKgoBQUFyWKxSLr2pealpaVtXCXasy1btmjmzJmqrq6WJJWXl9NDaLGVK1dKksaOHSubzdZhPssIQ4CBTCYTXx6MW6qpqVFGRoYefPBBBQUFNdpGD+FWzGaznn76aVVWVmrNmjW6cOFCW5eEDuS///u/FRoaqgEDBujYsWNtXQ46qOXLl8tqterKlStasWKFevXq1Wh7e/4sIwz9hdVqVUlJiWu5pKREVqu1DStCRxUaGqqysjKFhYWprKyM587QLLvdroyMDN1111268847JdFD+H6Cg4MVGxurkydPqqqqSg0NDbJYLCotLeXzDE3Kzc3Vl19+qf/5n/9RXV2dqqurtWXLFnoILXK9P0JDQ5WQkKC8vLwO81nGM0N/ER0drcLCQhUVFclut2v//v2Kj49v67LQAcXHx+uTTz6RJH3yySdKSEho44rQXjmdTm3YsEG9e/fWpEmTXOvpIbjr6tWrqqyslHRtZrkjR46od+/eio2N1RdffCFJ2rt3L59naNJPf/pTbdiwQZmZmVqwYIGGDh2qRx99lB6C22pqaly3WNbU1OjIkSPq169fh/ks40tXv+PgwYP6wx/+IIfDoaSkJP3kJz9p65LQzj3zzDM6fvy4ysvLFRoaqmnTpikhIUHr1q1TcXFxu55KEm3vxIkT+t3vfqd+/fq5bh+YMWOGBg0aRA/BLefOnVNmZqYcDoecTqd+9KMfacqUKbp48aKeeeYZVVRU6Pbbb9e8efPUqVOnti4X7dyxY8f03nvvKT09nR6C2y5evKg1a9ZIujaRy6hRo/STn/xE5eXlHeKzjDAEAAAAwCdxmxwAAAAAn0QYAgAAAOCTCEMAAAAAfBJhCAAAAIBPIgwBAAAA8EmEIQCAz5o2bZq+/fbbti4DANBG/Nq6AAAArktLS9Ply5dlNv/vv9WNGTNGs2fPbsOqAAB/qwhDAIB2ZcmSJYqLi2vrMgAAPoAwBABo9/bu3avdu3erf//++vTTTxUWFqbZs2dr2LBhkqTS0lJt2rRJJ06cUEhIiCZPniybzSZJcjgcevvtt/Xxxx/rypUr6tmzpxYvXqyIiAhJ0pEjR7Rq1SpdvXpVo0aN0uzZs2UymdrsvQIAvIcwBADoEE6dOqU777xTWVlZ+q//+i+tWbNGmZmZCgkJ0fr169W3b19t3LhRFy5c0PLly9WjRw8NHTpUO3bs0L59+/Sb3/xGPXv21Llz5+Tv7+8678GDB/X73/9e1dXVWrJkieLj4zV8+PA2fKcAAG8hDAEA2pWnn35aFovFtTxz5kz5+fkpNDRUEydOlMlk0siRI/Xee+/p4MGDGjJkiE6cOKH09HR17txZ/fv3V3Jysj755BMNHTpUu3fv1syZM9WrVy9JUv/+/RtdLzU1VcHBwQoODlZsbKzOnj1LGAIAH0EYAgC0K4sXL77hmaG9e/fKarU2un0tMjJSpaWlKisrU0hIiAIDA13bIiIidPr0aUlSSUmJoqKimrxet27dXK/9/f1VU1PTWm8FANDOMbU2AKBDKC0tldPpdC0XFxfLarUqLCxMFRUVqq6uvmGbJIWHh+vixYterxcA0P4RhgAAHcKVK1f0wQcfyG636/PPP9c333yjv//7v1dERITuuOMO/ed//qfq6up07tw5ffzxx7rrrrskScnJycrOzlZhYaGcTqfOnTun8vLyNn43AID2gNvkAADtylNPPdXoe4bi4uKUkJCgQYMGqbCwULNnz1a3bt20aNEidenSRZI0f/58bdq0SXPmzFFISIimTp3qutVu0qRJqq+v14oVK1ReXq7evXvrX/7lX9rkvQEA2heT87v3HAAA0A5dn1p7+fLlbV0KAOBvCLfJAQAAAPBJhCEAAAAAPonb5AAAAAD4JEaGAAAAAPgkwhAAAAAAn0QYAgAAAOCTCEMAAAAAfBJhCAAAAIBPIgwBAAAA8En/H75Uf6KmYGMVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open('/content/vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8oOduh_6kF_"
      },
      "source": [
        "from tensorflow.keras import layers, models, callbacks"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "\n",
        "simple_rnn_layer = layers.SimpleRNN(units=64, activation=\"tanh\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_YJUyrEJDMT",
        "outputId": "4973c187-7cc8-4da7-e60e-5facb42193cd"
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "\n",
        "sequence_exm = tf.constant([[[1, 4], [-4, 2], [2, 1]]], dtype=tf.float32)\n",
        "print(sequence_exm.shape)\n",
        "sequence_out = simple_rnn_layer(sequence_exm)\n",
        "print(sequence_out.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 2)\n",
            "(1, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAtycIpH1aA"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=1000)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "word_index = get_imdb_word_index(num_words=1000)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09829944-9471-497d-b873-d04caf1970bd"
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_token = max(word_index.values())\n",
        "max_token"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXWuW3yL61ec"
      },
      "source": [
        "embedding_dims = 16"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(None,)))\n",
        "model.add(layers.Embedding(input_dim=max_token+1, output_dim=embedding_dims, mask_zero=False))\n",
        "model.add(layers.LSTM(units=16))\n",
        "model.add(layers.Dense(units=1, activation=\"relu\"))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEOAcuhJcsal",
        "outputId": "f093457e-a455-4e00-ecd3-1d65581481ff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          16016     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 18,145\n",
            "Trainable params: 18,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhCla6eWbeQ1"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "inputs = layers.Input(shape=(None,))\n",
        "h = layers.Embedding(input_dim=max_token+1, output_dim=embedding_dims, mask_zero=True)(inputs)\n",
        "h = layers.LSTM(units=16)(h)\n",
        "outputs = layers.Dense(units=1, activation=\"relu\")(h)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Rg55T0bi_R",
        "outputId": "449cecb3-9214-483b-e6b4-b8a2cc54d01d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, None, 16)          16016     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 18,145\n",
            "Trainable params: 18,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "216PeHZFJDMi",
        "outputId": "be39c5fd-f2d1-4d6d-e12d-6793f7fe348c"
      },
      "source": [
        "# Fit the model and save its training history\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=1, \n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  3/782 [..............................] - ETA: 44:49 - loss: 2.6449 - accuracy: 0.4583"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b24a08083af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo"
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "\n",
        "inv_word_index = {value:key for key,value in word_index.items()}"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2438e6-4000-441f-d43b-2d2bb4bca5da"
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None, 0, :])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02788317]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92c2658-9ab5-4b03-8948-fa5eacbc4f95"
      },
      "source": [
        "# Get the corresponding label\n",
        "\n",
        "y_test[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1whIrYh5Owp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06LdJiXKRt9"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA8JlQVKRuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f51f06-ff48-4e16-b6b6-4f1f9db2e135"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iBFGx9_KRuD"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lcV0UGKRuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008957f5-01f1-43d9-dcfb-df1e64e1717d"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "word_index = get_imdb_word_index(num_words=1000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n",
        "max_index_value = max(word_index.values())\n",
        "embedding_dims = 8"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd8a8ce-3702-4475-a7ee-c3e293553eb3"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(None,)))\n",
        "model.add(layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dims, mask_zero=True))\n",
        "model.add(layers.LSTM(units=32, return_sequences=True))\n",
        "model.add(layers.LSTM(units=32, return_sequences=False))\n",
        "model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 8)           8008      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 32)          5248      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 21,609\n",
            "Trainable params: 21,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25653589-2ec2-4a5a-97ea-f71ad2d3015d"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(None,)))\n",
        "model.add(layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dims, mask_zero=True))\n",
        "model.add(layers.Bidirectional(layer = layers.GRU(units=8, return_sequences=True), \n",
        "                               backward_layer = layers.GRU(units=8, go_backwards=True, return_sequences=True),\n",
        "                               merge_mode=\"sum\"))\n",
        "model.add(layers.Bidirectional(layers.LSTM(units=8, return_sequences=False), merge_mode=\"concat\"))\n",
        "model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 8)           8008      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 8)           864       \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 16)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c75c65f-b0a5-4cde-af8f-c9311f689c81"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(None,)))\n",
        "model.add(layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dims, mask_zero=True))\n",
        "model.add(layers.Bidirectional(layers.LSTM(units=8, return_sequences=True), merge_mode=\"concat\"))\n",
        "model.add(layers.GRU(units=8, return_sequences=False))\n",
        "model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 8)           8008      \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 16)          1088      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 8)                 624       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 9,729\n",
            "Trainable params: 9,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "d046716d-9ba3-4bc0-8746-61923e8be846"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    batch_size=16, \n",
        "                    epochs=5, \n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   4/1563 [..............................] - ETA: 1:20:33 - loss: 0.6944 - accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c0ec84be1d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k88-BC4Z6E0_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}